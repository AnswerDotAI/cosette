{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp toolloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# Tool loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from cosette.core import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.xtras import save_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7951c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a22f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-5 gpt-5-mini gpt-5-nano o1-preview o1-mini gpt-4o gpt-4o-mini gpt-4-turbo gpt-4 gpt-4-32k gpt-3.5-turbo gpt-3.5-turbo-instruct o1 o3-mini chatgpt-4o-latest o1-pro o3 o4-mini gpt-4.1 gpt-4.1-mini gpt-4.1-nano'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f998b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-5-mini'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = first(m for m in models if 'mini' in m)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b64b5",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34342c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_orders_customers():\n",
    "    orders = {\n",
    "        \"O1\": dict(id=\"O1\", product=\"Widget A\", quantity=2, price=19.99, status=\"Shipped\"),\n",
    "        \"O2\": dict(id=\"O2\", product=\"Gadget B\", quantity=1, price=49.99, status=\"Processing\"),\n",
    "        \"O3\": dict(id=\"O3\", product=\"Gadget B\", quantity=2, price=49.99, status=\"Shipped\")}\n",
    "\n",
    "    customers = {\n",
    "        \"C1\": dict(name=\"John Doe\", email=\"john@example.com\", phone=\"123-456-7890\",\n",
    "                   orders=[orders['O1'], orders['O2']]),\n",
    "        \"C2\": dict(name=\"Jane Smith\", email=\"jane@example.com\", phone=\"987-654-3210\",\n",
    "                   orders=[orders['O3']])\n",
    "    }\n",
    "    return orders, customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders, customers = _get_orders_customers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_customer_info(\n",
    "    customer_id:str # ID of the customer\n",
    "): # Customer's name, email, phone number, and list of orders\n",
    "    \"Retrieves a customer's information and their orders based on the customer ID\"\n",
    "    print(f'- Retrieving customer {customer_id}')\n",
    "    return customers.get(customer_id, \"Customer not found\")\n",
    "\n",
    "def get_order_details(\n",
    "    order_id:str # ID of the order\n",
    "): # Order's ID, product name, quantity, price, and order status\n",
    "    \"Retrieves the details of a specific order based on the order ID\"\n",
    "    print(f'- Retrieving order {order_id}')\n",
    "    return orders.get(order_id, \"Order not found\")\n",
    "\n",
    "def cancel_order(\n",
    "    order_id:str # ID of the order to cancel\n",
    ")->bool: # True if the cancellation is successful\n",
    "    \"Cancels an order based on the provided order ID\"\n",
    "    print(f'- Cancelling order {order_id}')\n",
    "    if order_id not in orders: return False\n",
    "    orders[order_id]['status'] = 'Cancelled'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatkw = dict(\n",
    "    text={ \"verbosity\": \"low\" },\n",
    "    reasoning={ \"effort\": \"minimal\" }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4231dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_customer_info, get_order_details, cancel_order]\n",
    "chat = Chat(model, tools=tools, **chatkw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27c80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: resp_0610e51711a17c8b006943fce162a0819396584fc43c687fba\n",
       "- created_at: 1766063329.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseReasoningItem(id='rs_0610e51711a17c8b006943fce1b7e08193a742dd433b62cbcb', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0610e51711a17c8b006943fce1dfc081939b2f726e067bd88c', content=[ResponseOutputText(annotations=[], text='Hello! How can I help you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='minimal', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=136, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=15, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=151)\n",
       "- user: None\n",
       "- billing: {'payer': 'openai'}\n",
       "- store: True\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Response(id='resp_0610e51711a17c8b006943fce162a0819396584fc43c687fba', created_at=1766063329.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0610e51711a17c8b006943fce1b7e08193a742dd433b62cbcb', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0610e51711a17c8b006943fce1dfc081939b2f726e067bd88c', content=[ResponseOutputText(annotations=[], text='Hello! How can I help you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low'), top_logprobs=0, truncation='disabled', usage=In: 136; Out: 15; Total: 151, user=None, billing={'payer': 'openai'}, store=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat('Hi.')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93067a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_0610e51711a17c8b006943fce2fb408193a0298d1762a4b19e', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"customer_id\":\"C2\"}', call_id='call_1iQyH2m7zBT6AxtxpVfgOARS', name='get_customer_info', type='function_call', id='fc_0610e51711a17c8b006943fce34518819385d6cbeb29b1f63f', status='completed')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat('Can you tell me the email address for customer C2?')\n",
    "r.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6bc412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseOutputMessage(id='msg_0610e51711a17c8b006943fce4a59c8193b7914069038e07b0', content=[ResponseOutputText(annotations=[], text='The email address for customer C2 is jane@example.com.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat()\n",
    "r.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa531d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_067a83d17b75c4ea006943fce594008194904f7f4b1710ab11', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"customer_id\":\"C1\"}', call_id='call_5MXLQEl4LdzFyRHIR3DynD9I', name='get_customer_info', type='function_call', id='fc_067a83d17b75c4ea006943fce6c9848194b442cb73ffe02035', status='completed')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, tools=tools)\n",
    "r = chat('Please cancel all orders for customer C1 for me.')\n",
    "r.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Cancelling order O1\n",
      "- Cancelling order O2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_067a83d17b75c4ea006943fce7b6648194aa8afa477dc81c42', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"order_id\":\"O1\"}', call_id='call_y3LWRVEn8X80nCQf50EOVOu5', name='cancel_order', type='function_call', id='fc_067a83d17b75c4ea006943fce992f88194b8de77d411f78e44', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_oPiTCOxwXjo8uac0mzXK3rEv', name='cancel_order', type='function_call', id='fc_067a83d17b75c4ea006943fce9f498819495f077de035b7454', status='completed')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chat()\n",
    "r.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388cffe",
   "metadata": {},
   "source": [
    "## `toolloop` implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0136903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "_final_prompt = \"You have no more tool uses. Please summarize your findings. If you did not complete your goal please tell the user what further work needs to be done so they can choose how best to proceed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eac4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Chat.__call__)\n",
    "def toolloop(self:Chat,\n",
    "             pr, # Prompt to pass to Claude\n",
    "             max_steps=10, # Maximum number of tool requests to loop through\n",
    "             cont_func:callable=noop, # Function that stops loop if returns False\n",
    "             final_prompt=_final_prompt, # Prompt to add if last message is a tool call\n",
    "             **kwargs):\n",
    "    \"Add prompt `pr` to dialog and get a response from Claude, automatically following up with `tool_use` messages\"\n",
    "    @save_iter\n",
    "    def _f(o):\n",
    "        init_n = len(self.h)\n",
    "        r = self(pr, **kwargs)\n",
    "        yield r\n",
    "        if len(self.last)>1: yield from self.last[1:]\n",
    "        for i in range(max_steps-1):\n",
    "            x = self.h[-1]\n",
    "            if not (isinstance(x, dict) and x['type']=='function_call_output'): break\n",
    "            r = self(final_prompt if i==max_steps-2 else None, **kwargs)\n",
    "            yield r\n",
    "            if len(self.last)>1: yield from self.last[1:]\n",
    "            if not cont_func(*self.h[-3:]): break\n",
    "        o.value = self.h[init_n+1:]\n",
    "    return _f()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fd736",
   "metadata": {},
   "source": [
    "### Test Customer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(x):\n",
    "    if getattr(x, 'output_text', None): r = x\n",
    "    else: r = getattr(x,'output',x)\n",
    "    display(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc0eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The email address for customer C1 (John Doe) is john@example.com.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: resp_0787bac936d9204f006943fcee2ba48195ad60e3c1ec52d1d7\n",
       "- created_at: 1766063342.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseReasoningItem(id='rs_0787bac936d9204f006943fcee7cd881959b82edf88db5e70d', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0787bac936d9204f006943fcef3ee88195832b056ec436b34f', content=[ResponseOutputText(annotations=[], text='The email address for customer C1 (John Doe) is john@example.com.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='medium', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=316, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=86, output_tokens_details=OutputTokensDetails(reasoning_tokens=64), total_tokens=402)\n",
       "- user: None\n",
       "- billing: {'payer': 'openai'}\n",
       "- store: True\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Response(id='resp_0787bac936d9204f006943fcee2ba48195ad60e3c1ec52d1d7', created_at=1766063342.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0787bac936d9204f006943fcee7cd881959b82edf88db5e70d', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0787bac936d9204f006943fcef3ee88195832b056ec436b34f', content=[ResponseOutputText(annotations=[], text='The email address for customer C1 (John Doe) is john@example.com.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=In: 316; Out: 86; Total: 402, user=None, billing={'payer': 'openai'}, store=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseOutputMessage(id='msg_0787bac936d9204f006943fcef3ee88195832b056ec436b34f', content=[ResponseOutputText(annotations=[], text='The email address for customer C1 (John Doe) is john@example.com.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(model, tools=tools)\n",
    "pr = 'Can you tell me the email address for customer C1?'\n",
    "r = chat.toolloop(pr)\n",
    "res = list(r)\n",
    "for o in r: show(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdceb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def loop_outputs(res):\n",
    "    return [dict(p) for o in res for p in ([o] if isinstance(o,dict) else getattr(o,'output',[]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'rs_0787bac936d9204f006943fceb6f088195a44ade2155966909',\n",
       "  'summary': [],\n",
       "  'type': 'reasoning',\n",
       "  'content': None,\n",
       "  'encrypted_content': None,\n",
       "  'status': None},\n",
       " {'arguments': '{\"customer_id\":\"C1\"}',\n",
       "  'call_id': 'call_wqbYqGHnvgMg8lSY9JMUrwzU',\n",
       "  'name': 'get_customer_info',\n",
       "  'type': 'function_call',\n",
       "  'id': 'fc_0787bac936d9204f006943fcebe6d08195b9cd3ca97a01b7d2',\n",
       "  'status': 'completed'},\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_wqbYqGHnvgMg8lSY9JMUrwzU',\n",
       "  'output': \"{'name': 'John Doe', 'email': 'john@example.com', 'phone': '123-456-7890', 'orders': [{'id': 'O1', 'product': 'Widget A', 'quantity': 2, 'price': 19.99, 'status': 'Cancelled'}, {'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Cancelled'}]}\"},\n",
       " {'id': 'rs_0787bac936d9204f006943fcec9c108195b41ad9735c482bc4',\n",
       "  'summary': [],\n",
       "  'type': 'reasoning',\n",
       "  'content': None,\n",
       "  'encrypted_content': None,\n",
       "  'status': None},\n",
       " {'id': 'msg_0787bac936d9204f006943fced6e3c8195b5b4c9710ecb6485',\n",
       "  'content': [ResponseOutputText(annotations=[], text='The email address for customer C1 (John Doe) is john@example.com.', type='output_text', logprobs=[])],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = loop_outputs(res)\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_tc(x):\n",
    "    if x['type']=='function_call': return f\"- `{x['name']}({x['arguments']})`\\n\"\n",
    "    elif x['type']=='function_call_output': return f\"  - `{x['output']}`\\n\\n\"\n",
    "    else: return ''.join(o.text for o in x['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown(''.join(map(disp_tc, cl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c586d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseReasoningItem(id='rs_0787bac936d9204f006943fcee7cd881959b82edf88db5e70d', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
      " ResponseOutputMessage(id='msg_0787bac936d9204f006943fcef3ee88195832b056ec436b34f', content=[ResponseOutputText(annotations=[], text='The email address for customer C1 (John Doe) is john@example.com.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n"
     ]
    }
   ],
   "source": [
    "pprint(r.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders, customers = _get_orders_customers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de04256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving order O2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_080cc194cfa17c94006943fcf092688194adde78fdb74e90d3', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_ARnBd6xSrlcAfn3wBQGdLtiu', name='get_order_details', type='function_call', id='fc_080cc194cfa17c94006943fcf1ed8c8194adc4f0474afe98cc', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_ARnBd6xSrlcAfn3wBQGdLtiu', name='get_order_details', type='function_call', id='fc_080cc194cfa17c94006943fcf1ed8c8194adc4f0474afe98cc', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_ARnBd6xSrlcAfn3wBQGdLtiu',\n",
       " 'output': \"{'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Processing'}\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ResponseOutputMessage(id='msg_080cc194cfa17c94006943fcf3101081948ac3faafe2dcac65', content=[ResponseOutputText(annotations=[], text='Order O2 is currently: Processing.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(model, tools=tools)\n",
    "r = chat.toolloop('What is the status of order O2?')\n",
    "for o in r: display(getattr(o,'output',o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving customer C1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Cancelling order O1\n",
      "- Cancelling order O2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_080cc194cfa17c94006943fcf412208194a4c7b87ce81c4736', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"customer_id\":\"C1\"}', call_id='call_Btl5F6UrkBoJJaDQzke1VvVN', name='get_customer_info', type='function_call', id='fc_080cc194cfa17c94006943fcf82ba08194a65b676e302e9aa6', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"customer_id\":\"C1\"}', call_id='call_Btl5F6UrkBoJJaDQzke1VvVN', name='get_customer_info', type='function_call', id='fc_080cc194cfa17c94006943fcf82ba08194a65b676e302e9aa6', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_Btl5F6UrkBoJJaDQzke1VvVN',\n",
       " 'output': \"{'name': 'John Doe', 'email': 'john@example.com', 'phone': '123-456-7890', 'orders': [{'id': 'O1', 'product': 'Widget A', 'quantity': 2, 'price': 19.99, 'status': 'Shipped'}, {'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Processing'}]}\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_080cc194cfa17c94006943fcf913188194ab017b95ba08a13e', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"order_id\":\"O1\"}', call_id='call_4yaVagsUWe86YMk25kyCU9x2', name='cancel_order', type='function_call', id='fc_080cc194cfa17c94006943fcfa8bd081949731f7da8c5adc86', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_Vy0mCP8ocOYR31qk4sbVgRw5', name='cancel_order', type='function_call', id='fc_080cc194cfa17c94006943fcfab9688194a97ce8bb7ff46706', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"order_id\":\"O1\"}', call_id='call_4yaVagsUWe86YMk25kyCU9x2', name='cancel_order', type='function_call', id='fc_080cc194cfa17c94006943fcfa8bd081949731f7da8c5adc86', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_Vy0mCP8ocOYR31qk4sbVgRw5', name='cancel_order', type='function_call', id='fc_080cc194cfa17c94006943fcfab9688194a97ce8bb7ff46706', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_4yaVagsUWe86YMk25kyCU9x2',\n",
       " 'output': 'True'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_Vy0mCP8ocOYR31qk4sbVgRw5',\n",
       " 'output': 'True'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_080cc194cfa17c94006943fcfbd120819490c3ad1d75350865', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseOutputMessage(id='msg_080cc194cfa17c94006943fd043f948194ad1bb58d51d2de71', content=[ResponseOutputText(annotations=[], text='Done — I canceled all orders for customer C1 (John Doe).\\n\\nSummary:\\n- O1 — Widget A — previous status: Shipped — cancellation: Success\\n- O2 — Gadget B — previous status: Processing — cancellation: Success\\n\\nWould you like me to check refund status, send a confirmation to john@example.com, or do anything else?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseOutputMessage(id='msg_080cc194cfa17c94006943fd043f948194ad1bb58d51d2de71', content=[ResponseOutputText(annotations=[], text='Done — I canceled all orders for customer C1 (John Doe).\\n\\nSummary:\\n- O1 — Widget A — previous status: Shipped — cancellation: Success\\n- O2 — Gadget B — previous status: Processing — cancellation: Success\\n\\nWould you like me to check refund status, send a confirmation to john@example.com, or do anything else?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = chat.toolloop('Please cancel all orders for customer C1 for me.')\n",
    "res = list(r)\n",
    "for o in res: display(getattr(o,'output',o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl = loop_outputs(res)\n",
    "# Markdown('\\n'.join(map(disp_tc, cl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421d39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Retrieving order O2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- id: resp_080cc194cfa17c94006943fd06606c8194acbf56e9291c70ca\n",
       "- created_at: 1766063366.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseReasoningItem(id='rs_080cc194cfa17c94006943fd06bbd4819499041c0e2a896d43', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_47iqPnLAFKxbJ4JJ9EQwWw71', name='get_order_details', type='function_call', id='fc_080cc194cfa17c94006943fd07c3308194a643843cb1720a9e', status='completed')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='medium', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=521, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=87, output_tokens_details=OutputTokensDetails(reasoning_tokens=64), total_tokens=608)\n",
       "- user: None\n",
       "- billing: {'payer': 'openai'}\n",
       "- store: True"
      ],
      "text/plain": [
       "Response(id='resp_080cc194cfa17c94006943fd06606c8194acbf56e9291c70ca', created_at=1766063366.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_080cc194cfa17c94006943fd06bbd4819499041c0e2a896d43', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_47iqPnLAFKxbJ4JJ9EQwWw71', name='get_order_details', type='function_call', id='fc_080cc194cfa17c94006943fd07c3308194a643843cb1720a9e', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=In: 521; Out: 87; Total: 608, user=None, billing={'payer': 'openai'}, store=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"order_id\":\"O2\"}', call_id='call_47iqPnLAFKxbJ4JJ9EQwWw71', name='get_order_details', type='function_call', id='fc_080cc194cfa17c94006943fd07c3308194a643843cb1720a9e', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_47iqPnLAFKxbJ4JJ9EQwWw71',\n",
       " 'output': \"{'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Cancelled'}\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Order O2 is now: Cancelled.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: resp_080cc194cfa17c94006943fd0841e88194b12aa8c8f30b4e64\n",
       "- created_at: 1766063368.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseOutputMessage(id='msg_080cc194cfa17c94006943fd08ad488194a093653ee36021db', content=[ResponseOutputText(annotations=[], text='Order O2 is now: Cancelled.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='medium', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=676, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=13, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=689)\n",
       "- user: None\n",
       "- billing: {'payer': 'openai'}\n",
       "- store: True\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Response(id='resp_080cc194cfa17c94006943fd0841e88194b12aa8c8f30b4e64', created_at=1766063368.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseOutputMessage(id='msg_080cc194cfa17c94006943fd08ad488194a093653ee36021db', content=[ResponseOutputText(annotations=[], text='Order O2 is now: Cancelled.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='get_customer_info', parameters={'type': 'object', 'properties': {'customer_id': {'type': 'string', 'description': 'ID of the customer'}}, 'required': ['customer_id'], 'additionalProperties': False}, strict=True, type='function', description=\"Retrieves a customer's information and their orders based on the customer ID\"), FunctionTool(name='get_order_details', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Retrieves the details of a specific order based on the order ID'), FunctionTool(name='cancel_order', parameters={'type': 'object', 'properties': {'order_id': {'type': 'string', 'description': 'ID of the order to cancel'}}, 'required': ['order_id'], 'additionalProperties': False}, strict=True, type='function', description='Cancels an order based on the provided order ID\\n\\nReturns:\\n- type: boolean')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=In: 676; Out: 13; Total: 689, user=None, billing={'payer': 'openai'}, store=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for o in chat.toolloop('What is the status of order O2?'): display(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f73ae2",
   "metadata": {},
   "source": [
    "### Test Math Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd52dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x: int, y: int) -> int:\n",
    "    \"adds x and y.\"\n",
    "    return x + y\n",
    "\n",
    "def mul(x: int, y: int) -> int:\n",
    "    \"multiplies x and y.\"\n",
    "    return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc19bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_02621606c3b513dc006943fd09ad40819781fb7b32d5e5996a', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"x\":1258585825128,\"y\":34959234595}', call_id='call_Fg3v2kfgWIogSl1IEB0w1Y0K', name='add', type='function_call', id='fc_02621606c3b513dc006943fd09fdf881979ba71de45af8d588', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"x\":1258585825128,\"y\":34959234595}', call_id='call_Fg3v2kfgWIogSl1IEB0w1Y0K', name='add', type='function_call', id='fc_02621606c3b513dc006943fd09fdf881979ba71de45af8d588', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_Fg3v2kfgWIogSl1IEB0w1Y0K',\n",
       " 'output': '1293545059723'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"x\":1293545059723,\"y\":93}', call_id='call_9rimpAnaVInF4ssbHosAfTi8', name='mul', type='function_call', id='fc_02621606c3b513dc006943fd0bae9c81978026c7bfaae4a759', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_9rimpAnaVInF4ssbHosAfTi8',\n",
       " 'output': '120299690554239'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"x\":120299690554239,\"y\":-12439149}', call_id='call_OS43dlWKEYtYAocZpHJ94RXM', name='add', type='function_call', id='fc_02621606c3b513dc006943fd0c9f5c8197a11bc188b0174d6d', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_OS43dlWKEYtYAocZpHJ94RXM',\n",
       " 'output': '120299678115090'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "120299678115090\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: resp_02621606c3b513dc006943fd0d30f48197a911787dca9e5d00\n",
       "- created_at: 1766063373.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseOutputMessage(id='msg_02621606c3b513dc006943fd0d80f88197b58e845951e295e1', content=[ResponseOutputText(annotations=[], text='120299678115090', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='add', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='adds x and y.\\n\\nReturns:\\n- type: integer'), FunctionTool(name='mul', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='multiplies x and y.\\n\\nReturns:\\n- type: integer')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='minimal', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=250, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=9, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=259)\n",
       "- user: None\n",
       "- billing: {'payer': 'openai'}\n",
       "- store: True\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Response(id='resp_02621606c3b513dc006943fd0d30f48197a911787dca9e5d00', created_at=1766063373.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseOutputMessage(id='msg_02621606c3b513dc006943fd0d80f88197b58e845951e295e1', content=[ResponseOutputText(annotations=[], text='120299678115090', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='add', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='adds x and y.\\n\\nReturns:\\n- type: integer'), FunctionTool(name='mul', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='multiplies x and y.\\n\\nReturns:\\n- type: integer')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low'), top_logprobs=0, truncation='disabled', usage=In: 250; Out: 9; Total: 259, user=None, billing={'payer': 'openai'}, store=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(model, tools=[add, mul], **chatkw)\n",
    "pr = 'Can you add 1258585825128 to 34959234595, multiply by 93, and then add (-12439149)?'\n",
    "r = chat.toolloop(pr)\n",
    "for o in r: show(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc44e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120299678115090"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1258585825128 + 34959234595) * 93 - 12439149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be2307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_0944024f48105103006943fd116be8819483df3a9f25e3d328', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"x\":1258585825128,\"y\":34959234595}', call_id='call_B6xGJDpQJm5GrS2hnngybWTe', name='add', type='function_call', id='fc_0944024f48105103006943fd11abcc81949200a4eabf12e97b', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arguments', '{\"x\":1258585825128,\"y\":34959234595}')('call_id', 'call_B6xGJDpQJm5GrS2hnngybWTe')('name', 'add')('type', 'function_call')('id', 'fc_0944024f48105103006943fd11abcc81949200a4eabf12e97b')('status', 'completed')-  {'type': 'function_call_output', 'call_id': 'call_B6xGJDpQJm5GrS2hnngybWTe', 'output': '1293545059723'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"x\":1293545059723,\"y\":93}', call_id='call_Vb3v1awZxvoZuUjbq9RRZrfM', name='mul', type='function_call', id='fc_0944024f48105103006943fd1402188194a2adccf222c76591', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  {'type': 'function_call_output', 'call_id': 'call_Vb3v1awZxvoZuUjbq9RRZrfM', 'output': '120299690554239'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"x\":120299690554239,\"y\":-12439149}', call_id='call_Dd1Uzt8rMfWJCH0irbMa5OVV', name='add', type='function_call', id='fc_0944024f48105103006943fd14e54481948906bd955b405418', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  {'type': 'function_call_output', 'call_id': 'call_Dd1Uzt8rMfWJCH0irbMa5OVV', 'output': '120299678115090'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120299678115090"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "120299678115090\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: resp_0944024f48105103006943fd1583ec8194863012f06a95bb9a\n",
       "- created_at: 1766063381.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseOutputMessage(id='msg_0944024f48105103006943fd16463c81949df34dd0158af4c1', content=[ResponseOutputText(annotations=[], text='120299678115090', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='add', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='adds x and y.\\n\\nReturns:\\n- type: integer'), FunctionTool(name='mul', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='multiplies x and y.\\n\\nReturns:\\n- type: integer')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='minimal', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=250, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=9, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=259)\n",
       "- user: None\n",
       "- store: True\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Response(id='resp_0944024f48105103006943fd1583ec8194863012f06a95bb9a', created_at=1766063381.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseOutputMessage(id='msg_0944024f48105103006943fd16463c81949df34dd0158af4c1', content=[ResponseOutputText(annotations=[], text='120299678115090', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='add', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='adds x and y.\\n\\nReturns:\\n- type: integer'), FunctionTool(name='mul', parameters={'type': 'object', 'properties': {'x': {'type': 'integer', 'description': ''}, 'y': {'type': 'integer', 'description': ''}}, 'required': ['x', 'y'], 'additionalProperties': False}, strict=True, type='function', description='multiplies x and y.\\n\\nReturns:\\n- type: integer')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low'), top_logprobs=0, truncation='disabled', usage=In: 250; Out: 9; Total: 259, user=None, store=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(model, tools=[add, mul], **chatkw)\n",
    "r = chat.toolloop(pr, stream=True)\n",
    "for o in r:\n",
    "    if isinstance(o, dict): print('- ', o)\n",
    "    else:\n",
    "        for p in o: print(p, end='')\n",
    "        if hasattr(o, 'value'): show(o.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95da200",
   "metadata": {},
   "source": [
    "### Error Conditions: Out of Iterations, Exception During Tool Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c63e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mydiv(a:float, b:float):\n",
    "    \"Divide two numbers\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc1bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_02f9e0725e9fb6a5006943fd16f3dc81979a3aa89dfcb98aca', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"a\":43,\"b\":23454}', call_id='call_Fnsc5iNP8rMuj0rqeBLzXVsO', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd177c6c8197a5ad34f31755933a', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"a\":652,\"b\":0}', call_id='call_k7APDmfK4dy57LeiHYhBCNq6', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd17b4d08197ada7efed9792c679', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"a\":6843,\"b\":0}', call_id='call_ZpzLBH2zM3Wcy9aoFCbnZ0mN', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd17e5bc8197b3e6f2903db6ce9d', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"a\":321,\"b\":0}', call_id='call_JGS2KeOU7ku3n56kqbSrvEGy', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd181dd88197bd6492c3465327ea', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"a\":43,\"b\":23454}', call_id='call_Fnsc5iNP8rMuj0rqeBLzXVsO', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd177c6c8197a5ad34f31755933a', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"a\":652,\"b\":0}', call_id='call_k7APDmfK4dy57LeiHYhBCNq6', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd17b4d08197ada7efed9792c679', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"a\":6843,\"b\":0}', call_id='call_ZpzLBH2zM3Wcy9aoFCbnZ0mN', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd17e5bc8197b3e6f2903db6ce9d', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"a\":321,\"b\":0}', call_id='call_JGS2KeOU7ku3n56kqbSrvEGy', name='mydiv', type='function_call', id='fc_02f9e0725e9fb6a5006943fd181dd88197bd6492c3465327ea', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_Fnsc5iNP8rMuj0rqeBLzXVsO',\n",
       " 'output': '0.001833375969983798'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_k7APDmfK4dy57LeiHYhBCNq6',\n",
       " 'output': 'Traceback (most recent call last):\\n  File \"/usr/local/lib/python3.12/site-packages/toolslm/funccall.py\", line 215, in call_func\\n    try: return func(**inps)\\n                ^^^^^^^^^^^^\\n  File \"/tmp/ipykernel_5385/246724137.py\", line 3, in mydiv\\n    return a / b\\n           ~~^~~\\nZeroDivisionError: division by zero\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_ZpzLBH2zM3Wcy9aoFCbnZ0mN',\n",
       " 'output': 'Traceback (most recent call last):\\n  File \"/usr/local/lib/python3.12/site-packages/toolslm/funccall.py\", line 215, in call_func\\n    try: return func(**inps)\\n                ^^^^^^^^^^^^\\n  File \"/tmp/ipykernel_5385/246724137.py\", line 3, in mydiv\\n    return a / b\\n           ~~^~~\\nZeroDivisionError: division by zero\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_JGS2KeOU7ku3n56kqbSrvEGy',\n",
       " 'output': 'Traceback (most recent call last):\\n  File \"/usr/local/lib/python3.12/site-packages/toolslm/funccall.py\", line 215, in call_func\\n    try: return func(**inps)\\n                ^^^^^^^^^^^^\\n  File \"/tmp/ipykernel_5385/246724137.py\", line 3, in mydiv\\n    return a / b\\n           ~~^~~\\nZeroDivisionError: division by zero\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I computed the first division successfully:\n",
       "- 43 / 23454 = 0.001833375969983798\n",
       "\n",
       "I attempted the next steps but they failed because I tried to divide by zero (I passed 0 as the “previous result” for subsequent operations), causing errors. To complete the sequence you want, I need to perform these successive calculations using the preceding result each time:\n",
       "1. 652 / (43/23454)\n",
       "2. 6843 / (result of step 2)\n",
       "3. 321 / (result of step 3)\n",
       "\n",
       "If you want, I can now:\n",
       "- Recompute the chain without tool limits and give all four results, or\n",
       "- Compute them step-by-step here directly (no tools needed). Which do you prefer?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: resp_02f9e0725e9fb6a5006943fd18bff081979e13bb5930ee32b7\n",
       "- created_at: 1766063384.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseReasoningItem(id='rs_02f9e0725e9fb6a5006943fd19334c8197b4b20beb1ae09493', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_02f9e0725e9fb6a5006943fd195a9c81978fb9bcca07f80c87', content=[ResponseOutputText(annotations=[], text='I computed the first division successfully:\\n- 43 / 23454 = 0.001833375969983798\\n\\nI attempted the next steps but they failed because I tried to divide by zero (I passed 0 as the “previous result” for subsequent operations), causing errors. To complete the sequence you want, I need to perform these successive calculations using the preceding result each time:\\n1. 652 / (43/23454)\\n2. 6843 / (result of step 2)\\n3. 321 / (result of step 3)\\n\\nIf you want, I can now:\\n- Recompute the chain without tool limits and give all four results, or\\n- Compute them step-by-step here directly (no tools needed). Which do you prefer?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='mydiv', parameters={'type': 'object', 'properties': {'a': {'type': 'number', 'description': ''}, 'b': {'type': 'number', 'description': ''}}, 'required': ['a', 'b'], 'additionalProperties': False}, strict=True, type='function', description='Divide two numbers')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='minimal', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=537, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=163, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=700)\n",
       "- user: None\n",
       "- billing: {'payer': 'openai'}\n",
       "- store: True\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Response(id='resp_02f9e0725e9fb6a5006943fd18bff081979e13bb5930ee32b7', created_at=1766063384.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_02f9e0725e9fb6a5006943fd19334c8197b4b20beb1ae09493', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_02f9e0725e9fb6a5006943fd195a9c81978fb9bcca07f80c87', content=[ResponseOutputText(annotations=[], text='I computed the first division successfully:\\n- 43 / 23454 = 0.001833375969983798\\n\\nI attempted the next steps but they failed because I tried to divide by zero (I passed 0 as the “previous result” for subsequent operations), causing errors. To complete the sequence you want, I need to perform these successive calculations using the preceding result each time:\\n1. 652 / (43/23454)\\n2. 6843 / (result of step 2)\\n3. 321 / (result of step 3)\\n\\nIf you want, I can now:\\n- Recompute the chain without tool limits and give all four results, or\\n- Compute them step-by-step here directly (no tools needed). Which do you prefer?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='mydiv', parameters={'type': 'object', 'properties': {'a': {'type': 'number', 'description': ''}, 'b': {'type': 'number', 'description': ''}}, 'required': ['a', 'b'], 'additionalProperties': False}, strict=True, type='function', description='Divide two numbers')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low'), top_logprobs=0, truncation='disabled', usage=In: 537; Out: 163; Total: 700, user=None, billing={'payer': 'openai'}, store=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseOutputMessage(id='msg_02f9e0725e9fb6a5006943fd195a9c81978fb9bcca07f80c87', content=[ResponseOutputText(annotations=[], text='I computed the first division successfully:\\n- 43 / 23454 = 0.001833375969983798\\n\\nI attempted the next steps but they failed because I tried to divide by zero (I passed 0 as the “previous result” for subsequent operations), causing errors. To complete the sequence you want, I need to perform these successive calculations using the preceding result each time:\\n1. 652 / (43/23454)\\n2. 6843 / (result of step 2)\\n3. 321 / (result of step 3)\\n\\nIf you want, I can now:\\n- Recompute the chain without tool limits and give all four results, or\\n- Compute them step-by-step here directly (no tools needed). Which do you prefer?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(model, tools=[mydiv], **chatkw)\n",
    "r = chat.toolloop('Please calculate this sequence using your tools: 43/23454; 652/previous result; 6843/previous result; 321/previous result', max_steps=2)\n",
    "for o in r: show(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6178b8",
   "metadata": {},
   "source": [
    "This tests `raise_on_err=False` change to `toolslm.call_func` invocation. We should see this return an error as a string instead of crash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cbb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_0af57bb05fb6f746006943fd1bd07c81958a319ad4cb70eae8', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"a\":1,\"b\":0}', call_id='call_0FGtqnXi4rLuPC0ivZcaRw24', name='mydiv', type='function_call', id='fc_0af57bb05fb6f746006943fd1c29a08195989bf0c4f670baca', status='completed')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"a\":1,\"b\":0}', call_id='call_0FGtqnXi4rLuPC0ivZcaRw24', name='mydiv', type='function_call', id='fc_0af57bb05fb6f746006943fd1c29a08195989bf0c4f670baca', status='completed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_0FGtqnXi4rLuPC0ivZcaRw24',\n",
       " 'output': 'Traceback (most recent call last):\\n  File \"/usr/local/lib/python3.12/site-packages/toolslm/funccall.py\", line 215, in call_func\\n    try: return func(**inps)\\n                ^^^^^^^^^^^^\\n  File \"/tmp/ipykernel_5385/246724137.py\", line 3, in mydiv\\n    return a / b\\n           ~~^~~\\nZeroDivisionError: division by zero\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "ZeroDivisionError: division by zero\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: resp_0af57bb05fb6f746006943fd1cbdac8195b5d480c66c146b06\n",
       "- created_at: 1766063388.0\n",
       "- error: None\n",
       "- incomplete_details: None\n",
       "- instructions: None\n",
       "- metadata: {}\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: response\n",
       "- output: [ResponseOutputMessage(id='msg_0af57bb05fb6f746006943fd1d335881958929318eb6ad6c40', content=[ResponseOutputText(annotations=[], text='ZeroDivisionError: division by zero', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
       "- parallel_tool_calls: True\n",
       "- temperature: 1.0\n",
       "- tool_choice: auto\n",
       "- tools: [FunctionTool(name='mydiv', parameters={'type': 'object', 'properties': {'a': {'type': 'number', 'description': ''}, 'b': {'type': 'number', 'description': ''}}, 'required': ['a', 'b'], 'additionalProperties': False}, strict=True, type='function', description='Divide two numbers')]\n",
       "- top_p: 1.0\n",
       "- background: False\n",
       "- conversation: None\n",
       "- max_output_tokens: 4096\n",
       "- max_tool_calls: None\n",
       "- previous_response_id: None\n",
       "- prompt: None\n",
       "- prompt_cache_key: None\n",
       "- prompt_cache_retention: None\n",
       "- reasoning: Reasoning(effort='minimal', generate_summary=None, summary=None)\n",
       "- safety_identifier: None\n",
       "- service_tier: default\n",
       "- status: completed\n",
       "- text: ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low')\n",
       "- top_logprobs: 0\n",
       "- truncation: disabled\n",
       "- usage: ResponseUsage(input_tokens=198, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=11, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=209)\n",
       "- user: None\n",
       "- billing: {'payer': 'openai'}\n",
       "- store: True\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Response(id='resp_0af57bb05fb6f746006943fd1cbdac8195b5d480c66c146b06', created_at=1766063388.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseOutputMessage(id='msg_0af57bb05fb6f746006943fd1d335881958929318eb6ad6c40', content=[ResponseOutputText(annotations=[], text='ZeroDivisionError: division by zero', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='mydiv', parameters={'type': 'object', 'properties': {'a': {'type': 'number', 'description': ''}, 'b': {'type': 'number', 'description': ''}}, 'required': ['a', 'b'], 'additionalProperties': False}, strict=True, type='function', description='Divide two numbers')], top_p=1.0, background=False, conversation=None, max_output_tokens=4096, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low'), top_logprobs=0, truncation='disabled', usage=In: 198; Out: 11; Total: 209, user=None, billing={'payer': 'openai'}, store=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = Chat(model, tools=[mydiv], **chatkw)\n",
    "r = chat.toolloop('Try dividing 1 by 0 and see what the error result is')\n",
    "for o in r: show(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefe903",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
