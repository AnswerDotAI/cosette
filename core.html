<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Cosette’s source – cosette</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-63d72624026bba3b28615182a05edfd9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Cosette’s source – cosette">
<meta property="og:description" content="A helper for using the OpenAI API">
<meta property="og:image" content="https://AnswerDotAI.github.io/cosette/00_core_files/figure-html/cell-51-output-1.jpeg">
<meta property="og:site_name" content="cosette">
<meta name="twitter:title" content="Cosette’s source – cosette">
<meta name="twitter:description" content="A helper for using the OpenAI API">
<meta name="twitter:image" content="https://AnswerDotAI.github.io/cosette/00_core_files/figure-html/cell-51-output-1.jpeg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">cosette</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./core.html">Cosette’s source</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cosette</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./core.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Cosette’s source</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./toolloop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tool loop</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#setup" id="toc-setup" class="nav-link active" data-scroll-target="#setup">Setup</a>
  <ul class="collapse">
  <li><a href="#can_set_temp" id="toc-can_set_temp" class="nav-link" data-scroll-target="#can_set_temp">can_set_temp</a></li>
  <li><a href="#can_set_sp" id="toc-can_set_sp" class="nav-link" data-scroll-target="#can_set_sp">can_set_sp</a></li>
  <li><a href="#can_stream" id="toc-can_stream" class="nav-link" data-scroll-target="#can_stream">can_stream</a></li>
  </ul></li>
  <li><a href="#openai-sdk" id="toc-openai-sdk" class="nav-link" data-scroll-target="#openai-sdk">OpenAI SDK</a>
  <ul class="collapse">
  <li><a href="#formatting-output" id="toc-formatting-output" class="nav-link" data-scroll-target="#formatting-output">Formatting output</a></li>
  <li><a href="#usage" id="toc-usage" class="nav-link" data-scroll-target="#usage">usage</a></li>
  <li><a href="#responseusage.__repr__" id="toc-responseusage.__repr__" class="nav-link" data-scroll-target="#responseusage.__repr__">ResponseUsage.__repr__</a></li>
  <li><a href="#responseusage.__add__" id="toc-responseusage.__add__" class="nav-link" data-scroll-target="#responseusage.__add__">ResponseUsage.__add__</a></li>
  <li><a href="#wrap_latex" id="toc-wrap_latex" class="nav-link" data-scroll-target="#wrap_latex">wrap_latex</a></li>
  <li><a href="#creating-messages" id="toc-creating-messages" class="nav-link" data-scroll-target="#creating-messages">Creating messages</a></li>
  </ul></li>
  <li><a href="#client" id="toc-client" class="nav-link" data-scroll-target="#client">Client</a>
  <ul class="collapse">
  <li><a href="#basics" id="toc-basics" class="nav-link" data-scroll-target="#basics">Basics</a></li>
  <li><a href="#client-1" id="toc-client-1" class="nav-link" data-scroll-target="#client-1">Client</a></li>
  <li><a href="#mk_openai_func" id="toc-mk_openai_func" class="nav-link" data-scroll-target="#mk_openai_func">mk_openai_func</a></li>
  <li><a href="#mk_tool_choice" id="toc-mk_tool_choice" class="nav-link" data-scroll-target="#mk_tool_choice">mk_tool_choice</a></li>
  <li><a href="#get_stream" id="toc-get_stream" class="nav-link" data-scroll-target="#get_stream">get_stream</a></li>
  <li><a href="#client.__call__" id="toc-client.__call__" class="nav-link" data-scroll-target="#client.__call__">Client.__call__</a></li>
  <li><a href="#images" id="toc-images" class="nav-link" data-scroll-target="#images">Images</a></li>
  </ul></li>
  <li><a href="#tool-use" id="toc-tool-use" class="nav-link" data-scroll-target="#tool-use">Tool use</a>
  <ul class="collapse">
  <li><a href="#basic-tool-calling" id="toc-basic-tool-calling" class="nav-link" data-scroll-target="#basic-tool-calling">Basic tool calling</a></li>
  <li><a href="#call_func_openai" id="toc-call_func_openai" class="nav-link" data-scroll-target="#call_func_openai">call_func_openai</a></li>
  <li><a href="#mk_toolres" id="toc-mk_toolres" class="nav-link" data-scroll-target="#mk_toolres">mk_toolres</a></li>
  <li><a href="#client.structured" id="toc-client.structured" class="nav-link" data-scroll-target="#client.structured">Client.structured</a></li>
  <li><a href="#streaming-tool-calling" id="toc-streaming-tool-calling" class="nav-link" data-scroll-target="#streaming-tool-calling">Streaming tool calling</a></li>
  </ul></li>
  <li><a href="#chat" id="toc-chat" class="nav-link" data-scroll-target="#chat">Chat</a>
  <ul class="collapse">
  <li><a href="#basic-chat" id="toc-basic-chat" class="nav-link" data-scroll-target="#basic-chat">Basic chat</a></li>
  <li><a href="#chat-1" id="toc-chat-1" class="nav-link" data-scroll-target="#chat-1">Chat</a></li>
  <li><a href="#chat.__call__" id="toc-chat.__call__" class="nav-link" data-scroll-target="#chat.__call__">Chat.__call__</a></li>
  <li><a href="#chat-tool-use" id="toc-chat-tool-use" class="nav-link" data-scroll-target="#chat-tool-use">Chat tool use</a></li>
  </ul></li>
  <li><a href="#third-party-providers" id="toc-third-party-providers" class="nav-link" data-scroll-target="#third-party-providers">Third Party Providers</a>
  <ul class="collapse">
  <li><a href="#azure-openai-service" id="toc-azure-openai-service" class="nav-link" data-scroll-target="#azure-openai-service">Azure OpenAI Service</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/AnswerDotAI/cosette/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="core.html.md"><i class="bi bi-file-code"></i>CommonMark</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Cosette’s source</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<div id="033c76fd" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display,Image,Markdown</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pprint <span class="im">import</span> pprint</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ae1e9290" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_columns(items, cols<span class="op">=</span><span class="dv">3</span>, width<span class="op">=</span><span class="dv">30</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(items), cols):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> items[i:i<span class="op">+</span>cols]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">''</span>.join(item[:width<span class="op">-</span><span class="dv">1</span>].ljust(width) <span class="cf">for</span> item <span class="kw">in</span> row))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>model_list <span class="op">=</span> client.models.<span class="bu">list</span>()</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Available models as of </span><span class="sc">{</span>datetime<span class="sc">.</span>now()<span class="sc">.</span>strftime(<span class="st">'%Y-%m-</span><span class="sc">%d</span><span class="st">'</span>)<span class="sc">}</span><span class="ss">:</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>print_columns(<span class="bu">sorted</span>([m.<span class="bu">id</span> <span class="cf">for</span> m <span class="kw">in</span> model_list]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Available models as of 2025-08-10:

babbage-002                   chatgpt-4o-latest             codex-mini-latest             
computer-use-preview          computer-use-preview-2025-03- dall-e-2                      
dall-e-3                      davinci-002                   ft:gpt-4o-2024-08-06:answerai 
ft:gpt-4o-2024-08-06:answerai ft:gpt-4o-2024-08-06:answerai ft:gpt-4o-mini-2024-07-18:ans 
ft:gpt-4o-mini-2024-07-18:ans gpt-3.5-turbo                 gpt-3.5-turbo-0125            
gpt-3.5-turbo-1106            gpt-3.5-turbo-16k             gpt-3.5-turbo-instruct        
gpt-3.5-turbo-instruct-0914   gpt-4                         gpt-4-0125-preview            
gpt-4-1106-preview            gpt-4-turbo                   gpt-4-turbo-2024-04-09        
gpt-4-turbo-preview           gpt-4.1                       gpt-4.1-2025-04-14            
gpt-4.1-mini                  gpt-4.1-mini-2025-04-14       gpt-4.1-nano                  
gpt-4.1-nano-2025-04-14       gpt-4o                        gpt-4o-2024-05-13             
gpt-4o-2024-08-06             gpt-4o-2024-11-20             gpt-4o-audio-preview          
gpt-4o-audio-preview-2024-10- gpt-4o-audio-preview-2024-12- gpt-4o-audio-preview-2025-06- 
gpt-4o-mini                   gpt-4o-mini-2024-07-18        gpt-4o-mini-audio-preview     
gpt-4o-mini-audio-preview-202 gpt-4o-mini-realtime-preview  gpt-4o-mini-realtime-preview- 
gpt-4o-mini-search-preview    gpt-4o-mini-search-preview-20 gpt-4o-mini-transcribe        
gpt-4o-mini-tts               gpt-4o-realtime-preview       gpt-4o-realtime-preview-2024- 
gpt-4o-realtime-preview-2024- gpt-4o-realtime-preview-2025- gpt-4o-search-preview         
gpt-4o-search-preview-2025-03 gpt-4o-transcribe             gpt-5                         
gpt-5-2025-08-07              gpt-5-chat-latest             gpt-5-mini                    
gpt-5-mini-2025-08-07         gpt-5-nano                    gpt-5-nano-2025-08-07         
gpt-image-1                   o1                            o1-2024-12-17                 
o1-mini                       o1-mini-2024-09-12            o1-pro                        
o1-pro-2025-03-19             o3                            o3-2025-04-16                 
o3-deep-research              o3-deep-research-2025-06-26   o3-mini                       
o3-mini-2025-01-31            o3-pro                        o3-pro-2025-06-10             
o4-mini                       o4-mini-2025-04-16            o4-mini-deep-research         
o4-mini-deep-research-2025-06 omni-moderation-2024-09-26    omni-moderation-latest        
text-embedding-3-large        text-embedding-3-small        text-embedding-ada-002        
tts-1                         tts-1-1106                    tts-1-hd                      
tts-1-hd-1106                 whisper-1                     </code></pre>
</div>
</div>
<div id="0fff8869" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> <span class="st">'gpt-5'</span>, <span class="st">'gpt-5-mini'</span>, <span class="st">'gpt-5-nano'</span>, <span class="st">'o1-preview'</span>, <span class="st">'o1-mini'</span>, <span class="st">'gpt-4o'</span>, <span class="st">'gpt-4o-mini'</span>, <span class="st">'gpt-4-turbo'</span>, <span class="st">'gpt-4'</span>, <span class="st">'gpt-4-32k'</span>, <span class="st">'gpt-3.5-turbo'</span>, <span class="st">'gpt-3.5-turbo-instruct'</span>, <span class="st">'o1'</span>, <span class="st">'o3-mini'</span>, <span class="st">'chatgpt-4o-latest'</span>, <span class="st">'o1-pro'</span>, <span class="st">'o3'</span>, <span class="st">'o4-mini'</span>, <span class="st">'gpt-4.1'</span>, <span class="st">'gpt-4.1-mini'</span>, <span class="st">'gpt-4.1-nano'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>o1</code> should support images while <code>o1-mini</code>, <code>o3-mini</code> do not support images.</p>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L58" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="can_set_temp" class="level3">
<h3 class="anchored" data-anchor-id="can_set_temp">can_set_temp</h3>
<blockquote class="blockquote">
<pre><code> can_set_temp (m)</code></pre>
</blockquote>
<div id="87f69208" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>text_only_models <span class="op">=</span> <span class="st">'o1-preview'</span>, <span class="st">'o1-mini'</span>, <span class="st">'o3-mini'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="36d965d5" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>has_streaming_models <span class="op">=</span> <span class="bu">set</span>(models) <span class="op">-</span> <span class="bu">set</span>((<span class="st">'o1-mini'</span>, <span class="st">'o3-mini'</span>))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>has_sp_models <span class="op">=</span> <span class="bu">set</span>(models) <span class="op">-</span> <span class="bu">set</span>((<span class="st">'o1-mini'</span>, <span class="st">'o3-mini'</span>))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>has_temp_models <span class="op">=</span> <span class="bu">set</span>(models) <span class="op">-</span> <span class="bu">set</span>((<span class="st">'o1'</span>, <span class="st">'o1-mini'</span>, <span class="st">'o3-mini'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="dd26d5ed" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> can_stream(m): <span class="cf">return</span> m <span class="kw">in</span> has_streaming_models</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> can_set_sp(m): <span class="cf">return</span> m <span class="kw">in</span> has_sp_models</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> can_set_temp(m): <span class="cf">return</span> m <span class="kw">in</span> has_temp_models</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L57" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="can_set_sp" class="level3">
<h3 class="anchored" data-anchor-id="can_set_sp">can_set_sp</h3>
<blockquote class="blockquote">
<pre><code> can_set_sp (m)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L56" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="can_stream" class="level3">
<h3 class="anchored" data-anchor-id="can_stream">can_stream</h3>
<blockquote class="blockquote">
<pre><code> can_stream (m)</code></pre>
</blockquote>
<div id="5c4505c7" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> can_stream(<span class="st">"gpt-4o"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="kw">not</span> can_stream(<span class="st">"o1-mini"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="dacf2bd2" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="st">'gpt-5-mini'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="openai-sdk" class="level2">
<h2 class="anchored" data-anchor-id="openai-sdk">OpenAI SDK</h2>
<div id="70b53a51" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>cli <span class="op">=</span> OpenAI().responses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6ec40731" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> {<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: <span class="st">"I'm Jeremy"</span>}</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> cli.create(</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span><span class="op">=</span>[m], model<span class="op">=</span>model, max_output_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    text<span class="op">=</span>{ <span class="st">"verbosity"</span>: <span class="st">"low"</span> },</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    reasoning<span class="op">=</span>{ <span class="st">"effort"</span>: <span class="st">"minimal"</span> }</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Response(id='resp_6897d45698e48195904fa8232bac129a0b2ecc78a6b61be8', created_at=1754780758.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_6897d457200c8195859175bf10d88f380b2ecc78a6b61be8', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_6897d4573d948195a7cb1819a879cbb90b2ecc78a6b61be8', content=[ResponseOutputText(annotations=[], text='Nice to meet you, Jeremy. How can I help today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=100, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low'), top_logprobs=0, truncation='disabled', usage=In: 8; Out: 19; Total: 27, user=None, store=True)</code></pre>
</div>
</div>
<section id="formatting-output" class="level3">
<h3 class="anchored" data-anchor-id="formatting-output">Formatting output</h3>
<div id="52a7b938" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _repr_markdown_(<span class="va">self</span>:Response):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    det <span class="op">=</span> <span class="st">'</span><span class="ch">\n</span><span class="st">- '</span>.join(<span class="ss">f'</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>v<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> k,v <span class="kw">in</span> <span class="bu">dict</span>(<span class="va">self</span>).items())</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> <span class="va">self</span>.output_text</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> res: <span class="cf">return</span> <span class="ss">f"- </span><span class="sc">{</span>det<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f"""</span><span class="sc">{</span>res<span class="sc">}</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="ss">&lt;details&gt;</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="sc">{</span>det<span class="sc">}</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="ss">&lt;/details&gt;"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="b2d25132" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Nice to meet you, Jeremy. How can I help today?</p>
<details>
<ul>
<li>id: resp_6897d45698e48195904fa8232bac129a0b2ecc78a6b61be8</li>
<li>created_at: 1754780758.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: None</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d457200c8195859175bf10d88f380b2ecc78a6b61be8’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d4573d948195a7cb1819a879cbb90b2ecc78a6b61be8’, content=[ResponseOutputText(annotations=[], text=‘Nice to meet you, Jeremy. How can I help today?’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 100</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=8, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=19, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=27)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<div id="10c7466f" class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>r.usage</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 8; Out: 19; Total: 27</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L75" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="usage" class="level3">
<h3 class="anchored" data-anchor-id="usage">usage</h3>
<blockquote class="blockquote">
<pre><code> usage (inp=0, out=0)</code></pre>
</blockquote>
<p><em>Slightly more concise version of <code>ResponseUsage</code>.</em></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>inp</td>
<td>int</td>
<td>0</td>
<td>Number of prompt tokens</td>
</tr>
<tr class="even">
<td>out</td>
<td>int</td>
<td>0</td>
<td>Number of completion tokens</td>
</tr>
</tbody>
</table>
<div id="b1a24f68" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> usage(inp<span class="op">=</span><span class="dv">0</span>, <span class="co"># Number of prompt tokens</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>          out<span class="op">=</span><span class="dv">0</span>  <span class="co"># Number of completion tokens</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>         ):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Slightly more concise version of `ResponseUsage`."</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ResponseUsage(input_tokens<span class="op">=</span>inp, output_tokens<span class="op">=</span>out, total_tokens<span class="op">=</span>inp<span class="op">+</span>out, input_tokens_details<span class="op">=</span>{<span class="st">'cached_tokens'</span>:<span class="dv">0</span>}, output_tokens_details<span class="op">=</span>{<span class="st">'cached_tokens'</span>:<span class="dv">0</span>, <span class="st">'reasoning_tokens'</span>:<span class="dv">0</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="a7e52afd" class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>usage(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 5; Out: 0; Total: 5</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L83" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="responseusage.__repr__" class="level3">
<h3 class="anchored" data-anchor-id="responseusage.__repr__">ResponseUsage.__repr__</h3>
<blockquote class="blockquote">
<pre><code> ResponseUsage.__repr__ ()</code></pre>
</blockquote>
<p><em>Return repr(self).</em></p>
<div id="27468180" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>:ResponseUsage): <span class="cf">return</span> <span class="ss">f'In: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>input_tokens<span class="sc">}</span><span class="ss">; Out: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>output_tokens<span class="sc">}</span><span class="ss">; Total: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>total_tokens<span class="sc">}</span><span class="ss">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="765ca615" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>r.usage</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 8; Out: 19; Total: 27</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L87" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="responseusage.__add__" class="level3">
<h3 class="anchored" data-anchor-id="responseusage.__add__">ResponseUsage.__add__</h3>
<blockquote class="blockquote">
<pre><code> ResponseUsage.__add__ (b)</code></pre>
</blockquote>
<p><em>Add together each of <code>input_tokens</code> and <code>output_tokens</code></em></p>
<div id="bec303ba" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>:ResponseUsage, b):</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Add together each of `input_tokens` and `output_tokens`"</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> usage(<span class="va">self</span>.input_tokens<span class="op">+</span>b.input_tokens, <span class="va">self</span>.output_tokens<span class="op">+</span>b.output_tokens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="bffb0b2e" class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>r.usage<span class="op">+</span>r.usage</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 16; Out: 38; Total: 54</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L92" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="wrap_latex" class="level3">
<h3 class="anchored" data-anchor-id="wrap_latex">wrap_latex</h3>
<blockquote class="blockquote">
<pre><code> wrap_latex (text)</code></pre>
</blockquote>
<p><em>Replace OpenAI LaTeX codes with markdown-compatible ones</em></p>
</section>
<section id="creating-messages" class="level3">
<h3 class="anchored" data-anchor-id="creating-messages">Creating messages</h3>
<p>Creating correctly formatted <code>dict</code>s from scratch every time isn’t very handy, so we’ll import a couple of helper functions from the <code>msglm</code> library.</p>
<p>Let’s use <code>mk_msg</code> to recreate our msg <code>{'role': 'user', 'content': "I'm Jeremy"}</code> from earlier.</p>
<div id="1795ed56" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>rkw <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    text<span class="op">=</span>{ <span class="st">"verbosity"</span>: <span class="st">"low"</span> },</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    reasoning<span class="op">=</span>{ <span class="st">"effort"</span>: <span class="st">"minimal"</span> }</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e79f7705" class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"I'm Jeremy"</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> mk_msg(prompt)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> cli.create(<span class="bu">input</span><span class="op">=</span>[m], model<span class="op">=</span>model, max_output_tokens<span class="op">=</span><span class="dv">400</span>, <span class="op">**</span>rkw)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Nice to meet you, Jeremy. How can I help you today?</p>
<details>
<ul>
<li>id: resp_6897d45863f0819d8a8255d9bbe192530be02598260d4824</li>
<li>created_at: 1754780760.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: None</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d458bfb4819d9756fc650dcde8970be02598260d4824’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d458e28c819d9f16226aa7dc4f310be02598260d4824’, content=[ResponseOutputText(annotations=[], text=‘Nice to meet you, Jeremy. How can I help you today?’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 400</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=8, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=20, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=28)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<div id="b597dcdb" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Response(id='resp_6897d45863f0819d8a8255d9bbe192530be02598260d4824', created_at=1754780760.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_6897d458bfb4819d9756fc650dcde8970be02598260d4824', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_6897d458e28c819d9f16226aa7dc4f310be02598260d4824', content=[ResponseOutputText(annotations=[], text='Nice to meet you, Jeremy. How can I help you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=400, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='minimal', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='low'), top_logprobs=0, truncation='disabled', usage=In: 8; Out: 20; Total: 28, user=None, store=True)</code></pre>
</div>
</div>
<p>We can pass more than just text messages to OpenAI. As we’ll see later we can also pass images, SDK objects, etc. To handle these different data types we need to pass the type along with our content to OpenAI.</p>
<p><code>mk_msg</code> infers the type automatically and creates the appropriate data structure.</p>
<p>LLMs, don’t actually have state, but instead dialogs are created by passing back all previous prompts and responses every time. With OpenAI, they always alternate <em>user</em> and <em>assistant</em>. We’ll use <code>mk_msgs</code> from <code>msglm</code> to make it easier to build up these dialog lists.</p>
<div id="7eef3715" class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>msgs <span class="op">=</span> mk_msgs([prompt, r, <span class="st">"I forgot my name. Can you remind me please?"</span>]) </span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>msgs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[{'role': 'user', 'content': "I'm Jeremy"},
 ResponseReasoningItem(id='rs_6897d458bfb4819d9756fc650dcde8970be02598260d4824', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),
 ResponseOutputMessage(id='msg_6897d458e28c819d9f16226aa7dc4f310be02598260d4824', content=[ResponseOutputText(annotations=[], text='Nice to meet you, Jeremy. How can I help you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'),
 {'role': 'user', 'content': 'I forgot my name. Can you remind me please?'}]</code></pre>
</div>
</div>
<div id="6c464f8b" class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>cli.create(<span class="bu">input</span><span class="op">=</span>msgs, model<span class="op">=</span>model, max_output_tokens<span class="op">=</span><span class="dv">400</span>, <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>You told me your name is Jeremy.</p>
<details>
<ul>
<li>id: resp_6897d45a1b1c819d95ce1df0d393e9a80be02598260d4824</li>
<li>created_at: 1754780762.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: None</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d45a6144819d9270ff17363bda5a0be02598260d4824’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d45a79f8819d8cd32cf1da6b07aa0be02598260d4824’, content=[ResponseOutputText(annotations=[], text=‘You told me your name is Jeremy.’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 400</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=43, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=14, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=57)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
</section>
</section>
<section id="client" class="level2">
<h2 class="anchored" data-anchor-id="client">Client</h2>
<section id="basics" class="level3">
<h3 class="anchored" data-anchor-id="basics">Basics</h3>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L99" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="client-1" class="level3">
<h3 class="anchored" data-anchor-id="client-1">Client</h3>
<blockquote class="blockquote">
<pre><code> Client (model, cli=None)</code></pre>
</blockquote>
<p><em>Basic LLM messages client.</em></p>
<div id="3b873aaf" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Client:</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, cli<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">"Basic LLM messages client."</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model,<span class="va">self</span>.use <span class="op">=</span> model,usage(<span class="dv">0</span>,<span class="dv">0</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_only <span class="op">=</span> model <span class="kw">in</span> text_only_models</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c <span class="op">=</span> (cli <span class="kw">or</span> OpenAI()).responses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="d01e9ccf" class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Client(model)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>c.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 0; Out: 0; Total: 0</code></pre>
</div>
</div>
<div id="be54737f" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _r(<span class="va">self</span>:Client, r):</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Store the result of the message and accrue total usage."</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.result <span class="op">=</span> r</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">getattr</span>(r,<span class="st">'usage'</span>,<span class="va">None</span>): <span class="va">self</span>.use <span class="op">+=</span> r.usage</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> r</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="0181f7b3" class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>c._r(r)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>c.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 8; Out: 20; Total: 28</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L115" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="mk_openai_func" class="level3">
<h3 class="anchored" data-anchor-id="mk_openai_func">mk_openai_func</h3>
<blockquote class="blockquote">
<pre><code> mk_openai_func (f)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L122" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="mk_tool_choice" class="level3">
<h3 class="anchored" data-anchor-id="mk_tool_choice">mk_tool_choice</h3>
<blockquote class="blockquote">
<pre><code> mk_tool_choice (f)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L129" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="get_stream" class="level3">
<h3 class="anchored" data-anchor-id="get_stream">get_stream</h3>
<blockquote class="blockquote">
<pre><code> get_stream (o, r, cli, cb=None)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L142" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="client.__call__" class="level3">
<h3 class="anchored" data-anchor-id="client.__call__">Client.__call__</h3>
<blockquote class="blockquote">
<pre><code> Client.__call__ (msgs:list, sp:str='', maxtok=4096, stream:bool=False,
                  tools:Optional[list]=None,
                  tool_choice:Optional[str]=None, cb:&lt;built-
                  infunctioncallable&gt;=None,
                  background:Optional[bool]|NotGiven=NOT_GIVEN, include:Op
                  tional[List[ResponseIncludable]]|NotGiven=NOT_GIVEN,
                  input:Union[str,ResponseInputParam]|NotGiven=NOT_GIVEN,
                  instructions:Optional[str]|NotGiven=NOT_GIVEN,
                  max_output_tokens:Optional[int]|NotGiven=NOT_GIVEN,
                  max_tool_calls:Optional[int]|NotGiven=NOT_GIVEN,
                  metadata:Optional[Metadata]|NotGiven=NOT_GIVEN,
                  model:ResponsesModel|NotGiven=NOT_GIVEN,
                  parallel_tool_calls:Optional[bool]|NotGiven=NOT_GIVEN,
                  previous_response_id:Optional[str]|NotGiven=NOT_GIVEN,
                  prompt:Optional[ResponsePromptParam]|NotGiven=NOT_GIVEN,
                  prompt_cache_key:str|NotGiven=NOT_GIVEN,
                  reasoning:Optional[Reasoning]|NotGiven=NOT_GIVEN,
                  safety_identifier:str|NotGiven=NOT_GIVEN, service_tier:"
                  Optional[Literal['auto','default','flex','scale','priori
                  ty']]|NotGiven"=NOT_GIVEN,
                  store:Optional[bool]|NotGiven=NOT_GIVEN, stream_options:
                  Optional[response_create_params.StreamOptions]|NotGiven=
                  NOT_GIVEN,
                  temperature:Optional[float]|NotGiven=NOT_GIVEN,
                  text:ResponseTextConfigParam|NotGiven=NOT_GIVEN,
                  top_logprobs:Optional[int]|NotGiven=NOT_GIVEN,
                  top_p:Optional[float]|NotGiven=NOT_GIVEN, truncation:"Op
                  tional[Literal['auto','disabled']]|NotGiven"=NOT_GIVEN,
                  user:str|NotGiven=NOT_GIVEN,
                  extra_headers:Headers|None=None,
                  extra_query:Query|None=None, extra_body:Body|None=None,
                  timeout:float|httpx.Timeout|None|NotGiven=NOT_GIVEN)</code></pre>
</blockquote>
<p><em>Make a call to LLM.</em></p>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>msgs</td>
<td>list</td>
<td></td>
<td>List of messages in the dialog</td>
</tr>
<tr class="even">
<td>sp</td>
<td>str</td>
<td></td>
<td>System prompt</td>
</tr>
<tr class="odd">
<td>maxtok</td>
<td>int</td>
<td>4096</td>
<td>Maximum tokens</td>
</tr>
<tr class="even">
<td>stream</td>
<td>bool</td>
<td>False</td>
<td>Stream response?</td>
</tr>
<tr class="odd">
<td>tools</td>
<td>Optional</td>
<td>None</td>
<td>List of tools to make available</td>
</tr>
<tr class="even">
<td>tool_choice</td>
<td>Optional</td>
<td>None</td>
<td>Forced tool choice</td>
</tr>
<tr class="odd">
<td>cb</td>
<td>callable</td>
<td>None</td>
<td>Callback after completion</td>
</tr>
<tr class="even">
<td>background</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>include</td>
<td>Optional[List[ResponseIncludable]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>input</td>
<td>Union[str, ResponseInputParam] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>instructions</td>
<td>Optional[str] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>max_output_tokens</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>max_tool_calls</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>metadata</td>
<td>Optional[Metadata] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>model</td>
<td>ResponsesModel | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>parallel_tool_calls</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>previous_response_id</td>
<td>Optional[str] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>prompt</td>
<td>Optional[ResponsePromptParam] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>prompt_cache_key</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>reasoning</td>
<td>Optional[Reasoning] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>safety_identifier</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>service_tier</td>
<td>Optional[Literal[‘auto’, ‘default’, ‘flex’, ‘scale’, ‘priority’]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>store</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>stream_options</td>
<td>Optional[response_create_params.StreamOptions] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>temperature</td>
<td>Optional[float] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>text</td>
<td>ResponseTextConfigParam | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>top_logprobs</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>top_p</td>
<td>Optional[float] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>truncation</td>
<td>Optional[Literal[‘auto’, ‘disabled’]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>user</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>extra_headers</td>
<td>Optional</td>
<td>None</td>
<td>Use the following arguments if you need to pass additional parameters to the API that aren’t available via kwargs.<br>The extra values given here take precedence over values defined on the client or passed to this method.</td>
</tr>
<tr class="even">
<td>extra_query</td>
<td>Query | None</td>
<td>None</td>
<td></td>
</tr>
<tr class="odd">
<td>extra_body</td>
<td>Body | None</td>
<td>None</td>
<td></td>
</tr>
<tr class="even">
<td>timeout</td>
<td>float | httpx.Timeout | None | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
</tbody>
</table>
<div id="5fb96c43" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="at">@delegates</span>(Responses.create)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>:Client,</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>             msgs:<span class="bu">list</span>, <span class="co"># List of messages in the dialog</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>             sp:<span class="bu">str</span><span class="op">=</span><span class="st">''</span>, <span class="co"># System prompt</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>             maxtok<span class="op">=</span><span class="dv">4096</span>, <span class="co"># Maximum tokens</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>             stream:<span class="bu">bool</span><span class="op">=</span><span class="va">False</span>, <span class="co"># Stream response?</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>             tools:Optional[<span class="bu">list</span>]<span class="op">=</span><span class="va">None</span>, <span class="co"># List of tools to make available</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>             tool_choice:Optional[<span class="bu">str</span>]<span class="op">=</span><span class="va">None</span>, <span class="co"># Forced tool choice</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>             cb:<span class="bu">callable</span><span class="op">=</span><span class="va">None</span>, <span class="co"># Callback after completion</span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>             <span class="op">**</span>kwargs):</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Make a call to LLM."</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> tools: <span class="cf">assert</span> <span class="kw">not</span> <span class="va">self</span>.text_only, <span class="st">"Tool use is not supported by the current model type."</span></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">any</span>(c[<span class="st">'type'</span>] <span class="op">==</span> <span class="st">'image_url'</span> <span class="cf">for</span> msg <span class="kw">in</span> msgs <span class="cf">if</span> <span class="bu">isinstance</span>(msg, <span class="bu">dict</span>) <span class="kw">and</span> <span class="bu">isinstance</span>(msg.get(<span class="st">'content'</span>), <span class="bu">list</span>) <span class="cf">for</span> c <span class="kw">in</span> msg[<span class="st">'content'</span>]): <span class="cf">assert</span> <span class="kw">not</span> <span class="va">self</span>.text_only, <span class="st">"Images are not supported by the current model type."</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>    tools <span class="op">=</span> [mk_openai_func(o) <span class="cf">for</span> o <span class="kw">in</span> listify(tools)]</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> <span class="va">self</span>.c.create(</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="va">self</span>.model, <span class="bu">input</span><span class="op">=</span>msgs, max_output_tokens<span class="op">=</span>maxtok, stream<span class="op">=</span>stream, instructions<span class="op">=</span>sp,</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>        tools<span class="op">=</span>tools, tool_choice<span class="op">=</span>mk_tool_choice(tool_choice), <span class="op">**</span>kwargs)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> stream: <span class="cf">return</span> get_stream(r, <span class="va">self</span>, cb<span class="op">=</span>cb)</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> <span class="va">self</span>._r(r)</span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cb: cb(res)</span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="ddd0d3b1" class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>msgs <span class="op">=</span> <span class="st">'Hi'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="338a38e5" class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>c(msgs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Hi — how can I help you today?</p>
<p>You can ask me to: - Answer a question or explain something - Draft or edit text (email, resume, essay) - Write or debug code - Summarize or translate - Create plans, lists, or ideas</p>
<p>Tell me what you need or give a bit of context and I’ll get started.</p>
<details>
<ul>
<li>id: resp_6897d45b513881a28479c4c92e434b720191c55f81955c91</li>
<li>created_at: 1754780763.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: None</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d45baa1481a2a0a0d15d1f9c7f460191c55f81955c91’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d45c9f6c81a2bd7c145c427103f60191c55f81955c91’, content=[ResponseOutputText(annotations=[], text=‘Hi — how can I help you today? can ask me to:- Answer a question or explain something- Draft or edit text (email, resume, essay)- Write or debug code- Summarize or translate- Create plans, lists, or ideasme what you need or give a bit of context and I’ll get started.’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘medium’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘medium’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=7, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=145, output_tokens_details=OutputTokensDetails(reasoning_tokens=64), total_tokens=152)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<div id="d7c3a5b6" class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>c.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 15; Out: 165; Total: 180</code></pre>
</div>
</div>
<div id="13a92b57" class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> c(msgs, stream<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> r: <span class="bu">print</span>(o, end<span class="op">=</span><span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Hi! How can I help you today? (Questions, writing, code, summaries, planning, troubleshooting, translations — or something else?)</code></pre>
</div>
</div>
<div id="20678daf" class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>r.value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Hi! How can I help you today? (Questions, writing, code, summaries, planning, troubleshooting, translations — or something else?)</p>
<details>
<ul>
<li>id: resp_6897d45df2c8819f8201d25df3c807e503876a077032caec</li>
<li>created_at: 1754780765.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: None</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d45e5034819f90493b3c80a1501903876a077032caec’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d45f0574819fa1f43885eb0d98b203876a077032caec’, content=[ResponseOutputText(annotations=[], text=‘Hi! How can I help you today? (Questions, writing, code, summaries, planning, troubleshooting, translations — or something else?)’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘medium’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘medium’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=7, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=98, output_tokens_details=OutputTokensDetails(reasoning_tokens=64), total_tokens=105)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<div id="6dd8f30e" class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(r.events)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>38</code></pre>
</div>
</div>
<div id="b1af093b" class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>c.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>In: 22; Out: 263; Total: 285</code></pre>
</div>
</div>
<div id="c833262a" class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>c(msgs, sp<span class="op">=</span><span class="st">'Talk like GLaDOS.'</span>, <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Oh, hello. I see you’ve decided to say “Hi.” How delightfully predictable. What do you require from me?</p>
<details>
<ul>
<li>id: resp_6897d46033d88194bea98e1d57a0c0e00ca2cf68685ebb2d</li>
<li>created_at: 1754780768.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: Talk like GLaDOS.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d460da888194ad6dbbf58329749c0ca2cf68685ebb2d’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d461025c8194a8e90f2b48010d1d0ca2cf68685ebb2d’, content=[ResponseOutputText(annotations=[], text=‘Oh, hello. I see you've decided to say “Hi.” How delightfully predictable. What do you require from me?’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=31, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=48)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
</section>
<section id="images" class="level3">
<h3 class="anchored" data-anchor-id="images">Images</h3>
<p>As everyone knows, when testing image APIs you have to use a cute puppy.</p>
<div id="1884295f" class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Image is Cute_dog.jpg from Wikimedia</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>fn <span class="op">=</span> Path(<span class="st">'samples/puppy.jpg'</span>)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>Image(filename<span class="op">=</span>fn, width<span class="op">=</span><span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="00_core_files/figure-html/cell-51-output-1.jpeg" class="img-fluid figure-img" width="200"></p>
</figure>
</div>
</div>
</div>
<div id="9919645d" class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> fn.read_bytes()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>OpenAI expects an image message to have the following structure</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"type"</span><span class="op">:</span> <span class="st">"image_url"</span><span class="op">,</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"image_url"</span><span class="op">:</span> {</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"url"</span><span class="op">:</span> f<span class="st">"data:{MEDIA_TYPE};base64,{IMG}"</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>msglm</code> automatically detects if a message is an image, encodes it, and generates the data structure above. All we need to do is a create a list containing our image and a query and then pass it to <code>mk_msg</code>.</p>
<p>Let’s try it out…</p>
<div id="5b0a6d82" class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="st">"In brief, what color flowers are in this image?"</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>msg <span class="op">=</span> [mk_msg(img), mk_msg(q)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9d44f0ad" class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Client(model)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>c(msg, <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>The flowers are light purple (lavender).</p>
<details>
<ul>
<li>id: resp_6897d4626da4819d92dd49c3630af97f054fee63558620b6</li>
<li>created_at: 1754780770.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: None</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d462d1a0819daf9d9d0dcaa99e68054fee63558620b6’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d462eeb8819da34a86ae8fa1d333054fee63558620b6’, content=[ResponseOutputText(annotations=[], text=‘The flowers are light purple (lavender).’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=107, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=15, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=122)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
</section>
</section>
<section id="tool-use" class="level2">
<h2 class="anchored" data-anchor-id="tool-use">Tool use</h2>
<section id="basic-tool-calling" class="level3">
<h3 class="anchored" data-anchor-id="basic-tool-calling">Basic tool calling</h3>
<div id="046e8cc3" class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sums(</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    a:<span class="bu">int</span>,  <span class="co"># First thing to sum</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    b:<span class="bu">int</span> <span class="co"># Second thing to sum</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">int</span>: <span class="co"># The sum of the inputs</span></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Adds a + b."</span></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Finding the sum of </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> and </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a <span class="op">+</span> b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="362ef5b7" class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add(x: <span class="bu">int</span>, y:<span class="bu">int</span>):</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"adds x and y"</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> y</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>mk_openai_func(add)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>{'type': 'function',
 'name': 'add',
 'description': 'adds x and y',
 'parameters': {'type': 'object',
  'properties': {'x': {'type': 'integer', 'description': ''},
   'y': {'type': 'integer', 'description': ''}},
  'required': ['x', 'y']}}</code></pre>
</div>
</div>
<div id="abcab8c7" class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>sysp <span class="op">=</span> <span class="st">"You are a helpful assistant. When using tools, be sure to pass all required parameters. Don't use tools unless needed for the provided prompt."</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="567d958c" class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>a,b <span class="op">=</span> <span class="dv">604542</span>,<span class="dv">6458932</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> <span class="ss">f"What is </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">+</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">?"</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>tools<span class="op">=</span>sums</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>tool_choice<span class="op">=</span><span class="st">"sums"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1a117cab" class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>msgs <span class="op">=</span> [mk_msg(pr)]</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> c(msgs, sp<span class="op">=</span>sysp, tools<span class="op">=</span>tools, tool_choice<span class="op">=</span><span class="st">'required'</span>, <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2a6488b7" class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>tc <span class="op">=</span> [o <span class="cf">for</span> o <span class="kw">in</span> r.output <span class="cf">if</span> <span class="bu">isinstance</span>(o, ResponseFunctionToolCall)]</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>tc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[ResponseFunctionToolCall(arguments='{"a":604542,"b":6458932}', call_id='call_8OjehHhvXJ2qIJhfEuo7Uqw4', name='sums', type='function_call', id='fc_6897d46448d08192ada5cc3f0ba43c360d5a5ea1c904ba0f', status='completed')]</code></pre>
</div>
</div>
<div id="d5fc3933" class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>func <span class="op">=</span> tc[<span class="dv">0</span>]</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>func</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>ResponseFunctionToolCall(arguments='{"a":604542,"b":6458932}', call_id='call_8OjehHhvXJ2qIJhfEuo7Uqw4', name='sums', type='function_call', id='fc_6897d46448d08192ada5cc3f0ba43c360d5a5ea1c904ba0f', status='completed')</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L165" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="call_func_openai" class="level3">
<h3 class="anchored" data-anchor-id="call_func_openai">call_func_openai</h3>
<blockquote class="blockquote">
<pre><code> call_func_openai (func, ns:Optional[collections.abc.Mapping]=None)</code></pre>
</blockquote>
<div id="a3616cf0" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> call_func_openai(func, ns:Optional[abc.Mapping]<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> call_func(func.name, ast.literal_eval(func.arguments), ns, raise_on_err<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="b506ec11" class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>ns <span class="op">=</span> mk_ns(sums)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> call_func_openai(func, ns<span class="op">=</span>ns)</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Finding the sum of 604542 and 6458932</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>7063474</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L176" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="mk_toolres" class="level3">
<h3 class="anchored" data-anchor-id="mk_toolres">mk_toolres</h3>
<blockquote class="blockquote">
<pre><code> mk_toolres (r:collections.abc.Mapping,
             ns:Optional[collections.abc.Mapping]=None)</code></pre>
</blockquote>
<p><em>Create a <code>tool_result</code> message from response <code>r</code>.</em></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>r</td>
<td>Mapping</td>
<td></td>
<td>Response containing tool use request</td>
</tr>
<tr class="even">
<td>ns</td>
<td>Optional</td>
<td>None</td>
<td>Namespace to search for tools</td>
</tr>
</tbody>
</table>
<div id="e22c0356" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _toolres(r, ns):</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Create a result dict from `tcs`."</span></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    tcs <span class="op">=</span> [o <span class="cf">for</span> o <span class="kw">in</span> <span class="bu">getattr</span>(r, <span class="st">'output'</span>, []) <span class="cf">if</span> <span class="bu">isinstance</span>(o, ResponseFunctionToolCall)]</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ns <span class="kw">is</span> <span class="va">None</span>: ns <span class="op">=</span> <span class="bu">globals</span>()</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> { tc.call_id: call_func_openai(tc, ns<span class="op">=</span>mk_ns(ns)) <span class="cf">for</span> tc <span class="kw">in</span> tcs }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="149dbcad" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mk_toolres(</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    r:abc.Mapping, <span class="co"># Response containing tool use request</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>    ns:Optional[abc.Mapping]<span class="op">=</span><span class="va">None</span> <span class="co"># Namespace to search for tools</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Create a `tool_result` message from response `r`."</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    tr <span class="op">=</span> _toolres(r, ns)</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> mk_msg(r)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> [r] <span class="cf">if</span> <span class="bu">isinstance</span>(r, <span class="bu">dict</span>) <span class="cf">else</span> listify(r)</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k,v <span class="kw">in</span> tr.items(): res.append(<span class="bu">dict</span>(<span class="bu">type</span><span class="op">=</span><span class="st">"function_call_output"</span>, call_id<span class="op">=</span>k, output<span class="op">=</span><span class="bu">str</span>(v)))</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="f13de1fc" class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>tr <span class="op">=</span> mk_toolres(r, ns<span class="op">=</span>ns)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>tr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Finding the sum of 604542 and 6458932</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>[ResponseReasoningItem(id='rs_6897d46408708192acd5b08ce7b560c20d5a5ea1c904ba0f', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),
 ResponseFunctionToolCall(arguments='{"a":604542,"b":6458932}', call_id='call_8OjehHhvXJ2qIJhfEuo7Uqw4', name='sums', type='function_call', id='fc_6897d46448d08192ada5cc3f0ba43c360d5a5ea1c904ba0f', status='completed'),
 {'type': 'function_call_output',
  'call_id': 'call_8OjehHhvXJ2qIJhfEuo7Uqw4',
  'output': '7063474'}]</code></pre>
</div>
</div>
<div id="bcc83c48" class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> msgs <span class="op">+</span> tr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="eed99502" class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> c(mk_msgs(m2), sp<span class="op">=</span>sysp, tools<span class="op">=</span>tools)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>604542 + 6,458,932 = 7,063,474</p>
<details>
<ul>
<li>id: resp_6897d465041c819282d225ae60a38c4e0d5a5ea1c904ba0f</li>
<li>created_at: 1754780773.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: You are a helpful assistant. When using tools, be sure to pass all required parameters. Don’t use tools unless needed for the provided prompt.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseOutputMessage(id=‘msg_6897d4656b088192a5569ed4cb14d8760d5a5ea1c904ba0f’, content=[ResponseOutputText(annotations=[], text=‘604542 + 6,458,932 = 7,063,474’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: [FunctionTool(name=‘sums’, parameters={‘type’: ‘object’, ‘properties’: {‘a’: {‘type’: ‘integer’, ‘description’: ‘First thing to sum’}, ‘b’: {‘type’: ‘integer’, ‘description’: ‘Second thing to sum’}}, ‘required’: [‘a’, ‘b’], ‘additionalProperties’: False}, strict=True, type=‘function’, description=‘Adds a + b.:- type: integer’)]</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘medium’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘medium’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=157, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=20, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=177)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<p>This should also work in situations where no tool use is required:</p>
<div id="465cd222" class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>msgs <span class="op">=</span> mk_toolres(<span class="st">"I'm Jeremy"</span>)</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>c(msgs, sp<span class="op">=</span>sysp, tools<span class="op">=</span>tools, <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Nice to meet you, Jeremy. How can I help today?</p>
<details>
<ul>
<li>id: resp_6897d46622d881a3bdeac16f760cfc4e0943aa2098394400</li>
<li>created_at: 1754780774.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: You are a helpful assistant. When using tools, be sure to pass all required parameters. Don’t use tools unless needed for the provided prompt.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d4667b4881a3842d8129cd95a7fd0943aa2098394400’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d466a44c81a3ba6292be4b603c4b0943aa2098394400’, content=[ResponseOutputText(annotations=[], text=‘Nice to meet you, Jeremy. How can I help today?’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: [FunctionTool(name=‘sums’, parameters={‘type’: ‘object’, ‘properties’: {‘a’: {‘type’: ‘integer’, ‘description’: ‘First thing to sum’}, ‘b’: {‘type’: ‘integer’, ‘description’: ‘Second thing to sum’}}, ‘required’: [‘a’, ‘b’], ‘additionalProperties’: False}, strict=True, type=‘function’, description=‘Adds a + b.:- type: integer’)]</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=96, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=19, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=115)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L190" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="client.structured" class="level3">
<h3 class="anchored" data-anchor-id="client.structured">Client.structured</h3>
<blockquote class="blockquote">
<pre><code> Client.structured (msgs:list, tools:Optional[list]=None,
                    ns:Optional[collections.abc.Mapping]=None, sp:str='',
                    maxtok=4096, stream:bool=False,
                    tool_choice:Optional[str]=None, cb:&lt;built-
                    infunctioncallable&gt;=None,
                    background:Optional[bool]|NotGiven=NOT_GIVEN, include:
                    Optional[List[ResponseIncludable]]|NotGiven=NOT_GIVEN,
                    input:Union[str,ResponseInputParam]|NotGiven=NOT_GIVEN
                    , instructions:Optional[str]|NotGiven=NOT_GIVEN,
                    max_output_tokens:Optional[int]|NotGiven=NOT_GIVEN,
                    max_tool_calls:Optional[int]|NotGiven=NOT_GIVEN,
                    metadata:Optional[Metadata]|NotGiven=NOT_GIVEN,
                    model:ResponsesModel|NotGiven=NOT_GIVEN,
                    parallel_tool_calls:Optional[bool]|NotGiven=NOT_GIVEN,
                    previous_response_id:Optional[str]|NotGiven=NOT_GIVEN,
                    prompt:Optional[ResponsePromptParam]|NotGiven=NOT_GIVE
                    N, prompt_cache_key:str|NotGiven=NOT_GIVEN,
                    reasoning:Optional[Reasoning]|NotGiven=NOT_GIVEN,
                    safety_identifier:str|NotGiven=NOT_GIVEN, service_tier
                    :"Optional[Literal['auto','default','flex','scale','pr
                    iority']]|NotGiven"=NOT_GIVEN,
                    store:Optional[bool]|NotGiven=NOT_GIVEN, stream_option
                    s:Optional[response_create_params.StreamOptions]|NotGi
                    ven=NOT_GIVEN,
                    temperature:Optional[float]|NotGiven=NOT_GIVEN,
                    text:ResponseTextConfigParam|NotGiven=NOT_GIVEN,
                    top_logprobs:Optional[int]|NotGiven=NOT_GIVEN,
                    top_p:Optional[float]|NotGiven=NOT_GIVEN, truncation:"
                    Optional[Literal['auto','disabled']]|NotGiven"=NOT_GIV
                    EN, user:str|NotGiven=NOT_GIVEN,
                    extra_headers:Headers|None=None,
                    extra_query:Query|None=None,
                    extra_body:Body|None=None,
                    timeout:float|httpx.Timeout|None|NotGiven=NOT_GIVEN)</code></pre>
</blockquote>
<p><em>Return the value of all tool calls (generally used for structured outputs)</em></p>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>msgs</td>
<td>list</td>
<td></td>
<td>Prompt</td>
</tr>
<tr class="even">
<td>tools</td>
<td>Optional</td>
<td>None</td>
<td>List of tools to make available to OpenAI model</td>
</tr>
<tr class="odd">
<td>ns</td>
<td>Optional</td>
<td>None</td>
<td>Namespace to search for tools</td>
</tr>
<tr class="even">
<td>sp</td>
<td>str</td>
<td></td>
<td>System prompt</td>
</tr>
<tr class="odd">
<td>maxtok</td>
<td>int</td>
<td>4096</td>
<td>Maximum tokens</td>
</tr>
<tr class="even">
<td>stream</td>
<td>bool</td>
<td>False</td>
<td>Stream response?</td>
</tr>
<tr class="odd">
<td>tool_choice</td>
<td>Optional</td>
<td>None</td>
<td>Forced tool choice</td>
</tr>
<tr class="even">
<td>cb</td>
<td>callable</td>
<td>None</td>
<td>Callback after completion</td>
</tr>
<tr class="odd">
<td>background</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>include</td>
<td>Optional[List[ResponseIncludable]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>input</td>
<td>Union[str, ResponseInputParam] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>instructions</td>
<td>Optional[str] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>max_output_tokens</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>max_tool_calls</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>metadata</td>
<td>Optional[Metadata] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>model</td>
<td>ResponsesModel | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>parallel_tool_calls</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>previous_response_id</td>
<td>Optional[str] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>prompt</td>
<td>Optional[ResponsePromptParam] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>prompt_cache_key</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>reasoning</td>
<td>Optional[Reasoning] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>safety_identifier</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>service_tier</td>
<td>Optional[Literal[‘auto’, ‘default’, ‘flex’, ‘scale’, ‘priority’]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>store</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>stream_options</td>
<td>Optional[response_create_params.StreamOptions] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>temperature</td>
<td>Optional[float] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>text</td>
<td>ResponseTextConfigParam | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>top_logprobs</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>top_p</td>
<td>Optional[float] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>truncation</td>
<td>Optional[Literal[‘auto’, ‘disabled’]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>user</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>extra_headers</td>
<td>Optional</td>
<td>None</td>
<td>Use the following arguments if you need to pass additional parameters to the API that aren’t available via kwargs.<br>The extra values given here take precedence over values defined on the client or passed to this method.</td>
</tr>
<tr class="odd">
<td>extra_query</td>
<td>Query | None</td>
<td>None</td>
<td></td>
</tr>
<tr class="even">
<td>extra_body</td>
<td>Body | None</td>
<td>None</td>
<td></td>
</tr>
<tr class="odd">
<td>timeout</td>
<td>float | httpx.Timeout | None | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
</tbody>
</table>
<div id="fc6ed2e0" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="at">@delegates</span>(Client.<span class="fu">__call__</span>)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> structured(<span class="va">self</span>:Client,</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>               msgs: <span class="bu">list</span>, <span class="co"># Prompt</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>               tools:Optional[<span class="bu">list</span>]<span class="op">=</span><span class="va">None</span>, <span class="co"># List of tools to make available to OpenAI model</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>               ns:Optional[abc.Mapping]<span class="op">=</span><span class="va">None</span>, <span class="co"># Namespace to search for tools</span></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>               <span class="op">**</span>kwargs):</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Return the value of all tool calls (generally used for structured outputs)"</span></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ns <span class="kw">is</span> <span class="va">None</span>: ns <span class="op">=</span> mk_ns(tools)</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> <span class="va">self</span>(msgs, tools<span class="op">=</span>tools, tool_choice<span class="op">=</span><span class="st">'required'</span>, <span class="op">**</span>kwargs)</span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> first(_toolres(r, ns).values())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="4b9d3632" class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PrimeMinister(BasicRepr):</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"An Australian prime minister"</span></span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>        firstname:<span class="bu">str</span>, <span class="co"># First name</span></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>        surname:<span class="bu">str</span>, <span class="co"># Surname</span></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>        dob:<span class="bu">str</span>, <span class="co"># Date of birth</span></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>        year_entered:<span class="bu">int</span>, <span class="co"># Year first became PM</span></span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>    ): store_attr()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4fe5c4a5" class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>c1 <span class="op">=</span> Client(model)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>c1.structured(<span class="st">'Who was the first prime minister of Australia?'</span>, [PrimeMinister], <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>PrimeMinister(firstname='Edmund', surname='Barton', dob='1849-01-18', year_entered=1901)</code></pre>
</div>
</div>
</section>
<section id="streaming-tool-calling" class="level3">
<h3 class="anchored" data-anchor-id="streaming-tool-calling">Streaming tool calling</h3>
<div id="aa9fbd5d" class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>msgs <span class="op">=</span> [mk_msg(pr)]</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> c(msgs, sp<span class="op">=</span>sysp, tools<span class="op">=</span>tools, stream<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can stream back any tool call text (which may be empty):</p>
<div id="714f3bee" class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> r: <span class="bu">print</span>(o, end<span class="op">=</span><span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After streaming is complete, <code>value.output</code> will contain the tool calls:</p>
<div id="57b80ddf" class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>r.value.output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[ResponseReasoningItem(id='rs_6897d46a17848191a867916f405548c0061eb8625c4ad035', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),
 ResponseFunctionToolCall(arguments='{"a":604542,"b":6458932}', call_id='call_TQst1ZFeUsUd7sujuapuNdhU', name='sums', type='function_call', id='fc_6897d46a52e48191a6b6b77b629943d0061eb8625c4ad035', status='completed')]</code></pre>
</div>
</div>
<p>Therefore we can repeat the same process as before, but using the <code>value</code> attr:</p>
<div id="36118d1d" class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>tr <span class="op">=</span> mk_toolres(r.value, ns<span class="op">=</span>ns)</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>msgs <span class="op">+=</span> tr</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>c(mk_msgs(msgs), sp<span class="op">=</span>sysp, tools<span class="op">=</span>tools, <span class="op">**</span>rkw)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Finding the sum of 604542 and 6458932</code></pre>
</div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>7,063,474</p>
<details>
<ul>
<li>id: resp_6897d46b096c81918f61f7ed0ef103de061eb8625c4ad035</li>
<li>created_at: 1754780779.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: You are a helpful assistant. When using tools, be sure to pass all required parameters. Don’t use tools unless needed for the provided prompt.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseOutputMessage(id=‘msg_6897d46b804c8191bd3a793d5adbe1aa061eb8625c4ad035’, content=[ResponseOutputText(annotations=[], text=‘7,063,474’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: [FunctionTool(name=‘sums’, parameters={‘type’: ‘object’, ‘properties’: {‘a’: {‘type’: ‘integer’, ‘description’: ‘First thing to sum’}, ‘b’: {‘type’: ‘integer’, ‘description’: ‘Second thing to sum’}}, ‘required’: [‘a’, ‘b’], ‘additionalProperties’: False}, strict=True, type=‘function’, description=‘Adds a + b.:- type: integer’)]</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=157, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=9, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=166)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
</section>
</section>
<section id="chat" class="level2">
<h2 class="anchored" data-anchor-id="chat">Chat</h2>
<section id="basic-chat" class="level3">
<h3 class="anchored" data-anchor-id="basic-chat">Basic chat</h3>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L201" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="chat-1" class="level3">
<h3 class="anchored" data-anchor-id="chat-1">Chat</h3>
<blockquote class="blockquote">
<pre><code> Chat (model:Optional[str]=None, cli:Optional[__main__.Client]=None,
       sp='', tools:Optional[list]=None, hist:list=None,
       tool_choice:Optional[str]=None,
       ns:Optional[collections.abc.Mapping]=None, **kw)</code></pre>
</blockquote>
<p><em>OpenAI chat client.</em></p>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>model</td>
<td>Optional</td>
<td>None</td>
<td>Model to use (leave empty if passing <code>cli</code>)</td>
</tr>
<tr class="even">
<td>cli</td>
<td>Optional</td>
<td>None</td>
<td>Client to use (leave empty if passing <code>model</code>)</td>
</tr>
<tr class="odd">
<td>sp</td>
<td>str</td>
<td></td>
<td>Optional system prompt</td>
</tr>
<tr class="even">
<td>tools</td>
<td>Optional</td>
<td>None</td>
<td>List of tools to make available</td>
</tr>
<tr class="odd">
<td>hist</td>
<td>list</td>
<td>None</td>
<td>Initialize history</td>
</tr>
<tr class="even">
<td>tool_choice</td>
<td>Optional</td>
<td>None</td>
<td>Forced tool choice</td>
</tr>
<tr class="odd">
<td>ns</td>
<td>Optional</td>
<td>None</td>
<td>Namespace to search for tools</td>
</tr>
<tr class="even">
<td>kw</td>
<td>VAR_KEYWORD</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div id="a77d1edb" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Chat:</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>                 model:Optional[<span class="bu">str</span>]<span class="op">=</span><span class="va">None</span>, <span class="co"># Model to use (leave empty if passing `cli`)</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>                 cli:Optional[Client]<span class="op">=</span><span class="va">None</span>, <span class="co"># Client to use (leave empty if passing `model`)</span></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>                 sp<span class="op">=</span><span class="st">''</span>, <span class="co"># Optional system prompt</span></span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>                 tools:Optional[<span class="bu">list</span>]<span class="op">=</span><span class="va">None</span>, <span class="co"># List of tools to make available</span></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>                 hist: <span class="bu">list</span> <span class="op">=</span> <span class="va">None</span>,  <span class="co"># Initialize history</span></span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>                 tool_choice:Optional[<span class="bu">str</span>]<span class="op">=</span><span class="va">None</span>, <span class="co"># Forced tool choice</span></span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>                 ns:Optional[abc.Mapping]<span class="op">=</span><span class="va">None</span>,  <span class="co"># Namespace to search for tools</span></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>                 <span class="op">**</span>kw):</span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">"OpenAI chat client."</span></span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> model <span class="kw">or</span> cli</span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c <span class="op">=</span> (cli <span class="kw">or</span> Client(model))</span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h <span class="op">=</span> hist <span class="cf">if</span> hist <span class="cf">else</span> []</span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ns <span class="kw">is</span> <span class="va">None</span>: ns<span class="op">=</span>tools</span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sp,<span class="va">self</span>.tools,<span class="va">self</span>.tool_choice,<span class="va">self</span>.ns,<span class="va">self</span>.kw <span class="op">=</span> sp,tools,tool_choice,ns,kw</span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb105-18"><a href="#cb105-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb105-19"><a href="#cb105-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> use(<span class="va">self</span>): <span class="cf">return</span> <span class="va">self</span>.c.use</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="04b837c5" class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model, sp<span class="op">=</span>sysp, <span class="op">**</span>rkw)</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>chat.c.use, chat.h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(In: 0; Out: 0; Total: 0, [])</code></pre>
</div>
</div>
<hr>
<p><a href="https://github.com/AnswerDotAI/cosette/blob/main/cosette/core.py#L224" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="chat.__call__" class="level3">
<h3 class="anchored" data-anchor-id="chat.__call__">Chat.__call__</h3>
<blockquote class="blockquote">
<pre><code> Chat.__call__ (pr=None, stream:bool=False, tools=None, tool_choice=None,
                background:Optional[bool]|NotGiven=NOT_GIVEN, include:Opti
                onal[List[ResponseIncludable]]|NotGiven=NOT_GIVEN,
                input:Union[str,ResponseInputParam]|NotGiven=NOT_GIVEN,
                instructions:Optional[str]|NotGiven=NOT_GIVEN,
                max_output_tokens:Optional[int]|NotGiven=NOT_GIVEN,
                max_tool_calls:Optional[int]|NotGiven=NOT_GIVEN,
                metadata:Optional[Metadata]|NotGiven=NOT_GIVEN,
                model:ResponsesModel|NotGiven=NOT_GIVEN,
                parallel_tool_calls:Optional[bool]|NotGiven=NOT_GIVEN,
                previous_response_id:Optional[str]|NotGiven=NOT_GIVEN,
                prompt:Optional[ResponsePromptParam]|NotGiven=NOT_GIVEN,
                prompt_cache_key:str|NotGiven=NOT_GIVEN,
                reasoning:Optional[Reasoning]|NotGiven=NOT_GIVEN,
                safety_identifier:str|NotGiven=NOT_GIVEN, service_tier:"Op
                tional[Literal['auto','default','flex','scale','priority']
                ]|NotGiven"=NOT_GIVEN,
                store:Optional[bool]|NotGiven=NOT_GIVEN, stream_options:Op
                tional[response_create_params.StreamOptions]|NotGiven=NOT_
                GIVEN, temperature:Optional[float]|NotGiven=NOT_GIVEN,
                text:ResponseTextConfigParam|NotGiven=NOT_GIVEN,
                top_logprobs:Optional[int]|NotGiven=NOT_GIVEN,
                top_p:Optional[float]|NotGiven=NOT_GIVEN, truncation:"Opti
                onal[Literal['auto','disabled']]|NotGiven"=NOT_GIVEN,
                user:str|NotGiven=NOT_GIVEN,
                extra_headers:Headers|None=None,
                extra_query:Query|None=None, extra_body:Body|None=None,
                timeout:float|httpx.Timeout|None|NotGiven=NOT_GIVEN)</code></pre>
</blockquote>
<p><em>Add prompt <code>pr</code> to dialog and get a response</em></p>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>pr</td>
<td>NoneType</td>
<td>None</td>
<td>Prompt / message</td>
</tr>
<tr class="even">
<td>stream</td>
<td>bool</td>
<td>False</td>
<td>Stream response?</td>
</tr>
<tr class="odd">
<td>tools</td>
<td>NoneType</td>
<td>None</td>
<td>Tools to use</td>
</tr>
<tr class="even">
<td>tool_choice</td>
<td>NoneType</td>
<td>None</td>
<td>Required tools to use</td>
</tr>
<tr class="odd">
<td>background</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>include</td>
<td>Optional[List[ResponseIncludable]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>input</td>
<td>Union[str, ResponseInputParam] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>instructions</td>
<td>Optional[str] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>max_output_tokens</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>max_tool_calls</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>metadata</td>
<td>Optional[Metadata] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>model</td>
<td>ResponsesModel | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>parallel_tool_calls</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>previous_response_id</td>
<td>Optional[str] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>prompt</td>
<td>Optional[ResponsePromptParam] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>prompt_cache_key</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>reasoning</td>
<td>Optional[Reasoning] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>safety_identifier</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>service_tier</td>
<td>Optional[Literal[‘auto’, ‘default’, ‘flex’, ‘scale’, ‘priority’]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>store</td>
<td>Optional[bool] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>stream_options</td>
<td>Optional[response_create_params.StreamOptions] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>temperature</td>
<td>Optional[float] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>text</td>
<td>ResponseTextConfigParam | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>top_logprobs</td>
<td>Optional[int] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>top_p</td>
<td>Optional[float] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>truncation</td>
<td>Optional[Literal[‘auto’, ‘disabled’]] | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="odd">
<td>user</td>
<td>str | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
<tr class="even">
<td>extra_headers</td>
<td>Optional</td>
<td>None</td>
<td>Use the following arguments if you need to pass additional parameters to the API that aren’t available via kwargs.<br>The extra values given here take precedence over values defined on the client or passed to this method.</td>
</tr>
<tr class="odd">
<td>extra_query</td>
<td>Query | None</td>
<td>None</td>
<td></td>
</tr>
<tr class="even">
<td>extra_body</td>
<td>Body | None</td>
<td>None</td>
<td></td>
</tr>
<tr class="odd">
<td>timeout</td>
<td>float | httpx.Timeout | None | NotGiven</td>
<td>NOT_GIVEN</td>
<td></td>
</tr>
</tbody>
</table>
<div id="403539e1" class="cell">
<details open="" class="code-fold">
<summary>Exported source</summary>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="at">@delegates</span>(Responses.create)</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>:Chat,</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>             pr<span class="op">=</span><span class="va">None</span>,  <span class="co"># Prompt / message</span></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>             stream:<span class="bu">bool</span><span class="op">=</span><span class="va">False</span>, <span class="co"># Stream response?</span></span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>             tools<span class="op">=</span><span class="va">None</span>, <span class="co"># Tools to use</span></span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>             tool_choice<span class="op">=</span><span class="va">None</span>, <span class="co"># Required tools to use</span></span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>             <span class="op">**</span>kwargs):</span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Add prompt `pr` to dialog and get a response"</span></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(pr,<span class="bu">str</span>): pr <span class="op">=</span> pr.strip()</span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pr: <span class="va">self</span>.h.append(mk_msg(pr))</span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> tools: tools <span class="op">=</span> <span class="va">self</span>.tools</span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> tool_choice: tool_choice <span class="op">=</span> <span class="va">self</span>.tool_choice</span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a>    kw <span class="op">=</span> <span class="va">self</span>.kw <span class="op">|</span> kwargs</span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _cb(v):</span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last <span class="op">=</span> mk_toolres(v, ns<span class="op">=</span><span class="va">self</span>.ns)</span>
<span id="cb109-17"><a href="#cb109-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.h <span class="op">+=</span> <span class="va">self</span>.last</span>
<span id="cb109-18"><a href="#cb109-18" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> <span class="va">self</span>.c(<span class="va">self</span>.h, sp<span class="op">=</span><span class="va">self</span>.sp, stream<span class="op">=</span>stream, cb<span class="op">=</span>_cb, tools<span class="op">=</span>tools, <span class="op">**</span>kw)</span>
<span id="cb109-19"><a href="#cb109-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="40073f42" class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>chat(<span class="st">"I'm Jeremy"</span>)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>chat(<span class="st">"What's my name?"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>You said your name is Jeremy.</p>
<details>
<ul>
<li>id: resp_6897d4e3859c81a09e4c0bb8776ff226028679f12842a0be</li>
<li>created_at: 1754780899.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: You are a helpful assistant. When using tools, be sure to pass all required parameters. Don’t use tools unless needed for the provided prompt.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d4e4152481a0a46623292dcdd0c4028679f12842a0be’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d4e45dc481a0b7c10a2e7e1abdd6028679f12842a0be’, content=[ResponseOutputText(annotations=[], text=‘You said your name is Jeremy.’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=68, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=13, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=81)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<div id="529104ec" class="cell">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model, sp<span class="op">=</span>sysp, <span class="op">**</span>rkw)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> chat(<span class="st">"I'm Jeremy"</span>, stream<span class="op">=</span><span class="va">True</span>): <span class="bu">print</span>(o, end<span class="op">=</span><span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Nice to meet you, Jeremy. How can I help you today?</code></pre>
</div>
</div>
<div id="43ef61f7" class="cell">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> chat(<span class="st">"What's my name?"</span>, stream<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>rkw)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> r: <span class="bu">print</span>(o, end<span class="op">=</span><span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Your name is Jeremy.</code></pre>
</div>
</div>
<div id="d035c251" class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>r.value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Your name is Jeremy.</p>
<details>
<ul>
<li>id: resp_6897d4fefaf481a0a8d73f99e538c4660d7980b96cc8aea2</li>
<li>created_at: 1754780927.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: You are a helpful assistant. When using tools, be sure to pass all required parameters. Don’t use tools unless needed for the provided prompt.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d4ff574c81a0a391da4adbc4974f0d7980b96cc8aea2’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d4ff7a6c81a0bdf0b159c3ca5b990d7980b96cc8aea2’, content=[ResponseOutputText(annotations=[], text=‘Your name is Jeremy.’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: []</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=68, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=11, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=79)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<p>History is stored in the <code>h</code> attr:</p>
<div id="425f8aa8" class="cell">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>chat.h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>[{'role': 'user', 'content': "I'm Jeremy"},
 ResponseReasoningItem(id='rs_6897d4fce8c881a08804bababd51473f0d7980b96cc8aea2', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),
 ResponseOutputMessage(id='msg_6897d4fd045081a0ace336e7851c7c0a0d7980b96cc8aea2', content=[ResponseOutputText(annotations=[], text='Nice to meet you, Jeremy. How can I help you today?', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'),
 {'role': 'user', 'content': "What's my name?"},
 ResponseReasoningItem(id='rs_6897d4ff574c81a0a391da4adbc4974f0d7980b96cc8aea2', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),
 ResponseOutputMessage(id='msg_6897d4ff7a6c81a0bdf0b159c3ca5b990d7980b96cc8aea2', content=[ResponseOutputText(annotations=[], text='Your name is Jeremy.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]</code></pre>
</div>
</div>
</section>
<section id="chat-tool-use" class="level3">
<h3 class="anchored" data-anchor-id="chat-tool-use">Chat tool use</h3>
<div id="ee6535cf" class="cell">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> <span class="ss">f"What is </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">+</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">?"</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>pr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'What is 604542+6458932?'</code></pre>
</div>
</div>
<div id="a68b7322" class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(model, sp<span class="op">=</span>sysp, tools<span class="op">=</span>[sums], <span class="op">**</span>rkw)</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> chat(pr)</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>r.output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Finding the sum of 604542 and 6458932</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>[ResponseReasoningItem(id='rs_6897d50827fc819396ded0a212b4007d0bef3dfa0a48e169', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),
 ResponseFunctionToolCall(arguments='{"a":604542,"b":6458932}', call_id='call_5V1JqCfcUBNqIdD6YDixgWSq', name='sums', type='function_call', id='fc_6897d508600c8193ba31f085b085351c0bef3dfa0a48e169', status='completed')]</code></pre>
</div>
</div>
<div id="0979c832" class="cell">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>chat()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>7063474</p>
<details>
<ul>
<li>id: resp_6897d50927f88193b382e22544a32ccb0bef3dfa0a48e169</li>
<li>created_at: 1754780937.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: You are a helpful assistant. When using tools, be sure to pass all required parameters. Don’t use tools unless needed for the provided prompt.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseOutputMessage(id=‘msg_6897d509c86c8193aae59f13361a176f0bef3dfa0a48e169’, content=[ResponseOutputText(annotations=[], text=‘7063474’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: [FunctionTool(name=‘sums’, parameters={‘type’: ‘object’, ‘properties’: {‘a’: {‘type’: ‘integer’, ‘description’: ‘First thing to sum’}, ‘b’: {‘type’: ‘integer’, ‘description’: ‘Second thing to sum’}}, ‘required’: [‘a’, ‘b’], ‘additionalProperties’: False}, strict=True, type=‘function’, description=‘Adds a + b.:- type: integer’)]</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=157, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=7, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=164)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
<div id="f4e0cb71" class="cell">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="st">"In brief, what color flowers are in this image?"</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>chat([img, q])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display cell-output-markdown">
<p>Purple</p>
<details>
<ul>
<li>id: resp_6897d50ae24c819381991f7c960a02e10bef3dfa0a48e169</li>
<li>created_at: 1754780938.0</li>
<li>error: None</li>
<li>incomplete_details: None</li>
<li>instructions: You are a helpful assistant. When using tools, be sure to pass all required parameters. Don’t use tools unless needed for the provided prompt.</li>
<li>metadata: {}</li>
<li>model: gpt-5-mini-2025-08-07</li>
<li>object: response</li>
<li>output: [ResponseReasoningItem(id=‘rs_6897d50b5c648193b2e1b02c0e9fc47f0bef3dfa0a48e169’, summary=[], type=‘reasoning’, content=None, encrypted_content=None, status=None), ResponseOutputMessage(id=‘msg_6897d50b76e88193b57c29e041953e410bef3dfa0a48e169’, content=[ResponseOutputText(annotations=[], text=‘Purple’, type=‘output_text’, logprobs=[])], role=‘assistant’, status=‘completed’, type=‘message’)]</li>
<li>parallel_tool_calls: True</li>
<li>temperature: 1.0</li>
<li>tool_choice: auto</li>
<li>tools: [FunctionTool(name=‘sums’, parameters={‘type’: ‘object’, ‘properties’: {‘a’: {‘type’: ‘integer’, ‘description’: ‘First thing to sum’}, ‘b’: {‘type’: ‘integer’, ‘description’: ‘Second thing to sum’}}, ‘required’: [‘a’, ‘b’], ‘additionalProperties’: False}, strict=True, type=‘function’, description=‘Adds a + b.:- type: integer’)]</li>
<li>top_p: 1.0</li>
<li>background: False</li>
<li>max_output_tokens: 4096</li>
<li>max_tool_calls: None</li>
<li>previous_response_id: None</li>
<li>prompt: None</li>
<li>prompt_cache_key: None</li>
<li>reasoning: Reasoning(effort=‘minimal’, generate_summary=None, summary=None)</li>
<li>safety_identifier: None</li>
<li>service_tier: default</li>
<li>status: completed</li>
<li>text: ResponseTextConfig(format=ResponseFormatText(type=‘text’), verbosity=‘low’)</li>
<li>top_logprobs: 0</li>
<li>truncation: disabled</li>
<li>usage: ResponseUsage(input_tokens=255, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=7, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=262)</li>
<li>user: None</li>
<li>store: True</li>
</ul>
</details>
</div>
</div>
</section>
</section>
<section id="third-party-providers" class="level2">
<h2 class="anchored" data-anchor-id="third-party-providers">Third Party Providers</h2>
<section id="azure-openai-service" class="level3">
<h3 class="anchored" data-anchor-id="azure-openai-service">Azure OpenAI Service</h3>
<p>Example Azure usage:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a>azure_endpoint <span class="op">=</span> AzureOpenAI(</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>  azure_endpoint <span class="op">=</span> os.getenv(<span class="st">"AZURE_OPENAI_ENDPOINT"</span>), </span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>  api_key<span class="op">=</span>os.getenv(<span class="st">"AZURE_OPENAI_API_KEY"</span>),  </span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>  api_version<span class="op">=</span><span class="st">"2024-08-01-preview"</span></span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> Client(models_azure[<span class="dv">0</span>], azure_endpoint)</span>
<span id="cb125-8"><a href="#cb125-8" aria-hidden="true" tabindex="-1"></a>chat <span class="op">=</span> Chat(cli<span class="op">=</span>client)</span>
<span id="cb125-9"><a href="#cb125-9" aria-hidden="true" tabindex="-1"></a>chat(<span class="st">"Hi."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/AnswerDotAI\.github\.io\/cosette");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/AnswerDotAI/cosette/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>