{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# Cosette's source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6471-8061-4fdd-85a1-25fdc27c5cf3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import imghdr\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "import inspect, typing, mimetypes, base64, json, ast\n",
    "from collections import abc\n",
    "from random import choices\n",
    "from string import ascii_letters,digits\n",
    "\n",
    "from openai import types\n",
    "from openai import Completion,OpenAI,NOT_GIVEN\n",
    "from openai.resources import chat\n",
    "from openai.resources.chat import Completions\n",
    "from openai.types.chat.chat_completion import ChatCompletion, ChatCompletionMessage\n",
    "from openai.types.completion_usage import CompletionUsage\n",
    "\n",
    "from toolslm.funccall import *\n",
    "\n",
    "try: from IPython import display\n",
    "except: display=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13866a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "empty = inspect.Parameter.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "models = 'gpt-4o', 'gpt-4-turbo', 'gpt-4', 'gpt-4-32k', 'gpt-3.5-turbo', 'gpt-3.5-turbo-instruct', 'o1-preview', 'o1-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71985a9c",
   "metadata": {},
   "source": [
    "For examples, we'll use GPT-4o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d4d81",
   "metadata": {},
   "source": [
    "## OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b53a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = OpenAI().chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec40731",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Jeremy\"}\n",
    "r = cli.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6359e1a",
   "metadata": {},
   "source": [
    "### Formatting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba620ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def find_block(r:abc.Mapping, # The message to look in\n",
    "              ):\n",
    "    \"Find the message in `r`.\"\n",
    "    m = nested_idx(r, 'choices', 0)\n",
    "    if not m: return m\n",
    "    if hasattr(m, 'message'): return m.message\n",
    "    return m.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def contents(r):\n",
    "    \"Helper to get the contents from response `r`.\"\n",
    "    blk = find_block(r)\n",
    "    if not blk: return r\n",
    "    if hasattr(blk, 'content'): return getattr(blk,'content')\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17924d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _repr_markdown_(self:ChatCompletion):\n",
    "    det = '\\n- '.join(f'{k}: {v}' for k,v in dict(self).items())\n",
    "    res = contents(self)\n",
    "    if not res: return f\"- {det}\"\n",
    "    return f\"\"\"{contents(self)}\n",
    "\n",
    "<details>\n",
    "\n",
    "- {det}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd85eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a24f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def usage(inp=0, # Number of prompt tokens\n",
    "          out=0, # Number of completion tokens\n",
    "          reas=0 # Number of reasoning tokens\n",
    "         ):\n",
    "    \"Slightly more concise version of `CompletionUsage`.\"\n",
    "    return CompletionUsage(prompt_tokens=inp, completion_tokens=out, reasoning_tokens=reas, total_tokens=inp+out+reas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e52afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27468180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __repr__(self:CompletionUsage): return f'In: {self.prompt_tokens}; Out: {self.completion_tokens}; Reasoning: {self.completion_tokens_details.reasoning_tokens}; Total: {self.total_tokens}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ca615",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec303ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __add__(self:CompletionUsage, b):\n",
    "    \"Add together each of `input_tokens` and `output_tokens`\"\n",
    "    return usage(self.prompt_tokens+b.prompt_tokens, self.completion_tokens+b.completion_tokens, self.completion_tokens_details.reasoning_tokens+b.completion_tokens_details.reasoning_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.usage+r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307caa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def wrap_latex(text, md=True):\n",
    "    \"Replace OpenAI LaTeX codes with markdown-compatible ones\"\n",
    "    text = re.sub(r\"\\\\\\((.*?)\\\\\\)\", lambda o: f\"${o.group(1)}$\", text)\n",
    "    res = re.sub(r\"\\\\\\[(.*?)\\\\\\]\", lambda o: f\"$${o.group(1)}$$\", text, flags=re.DOTALL)\n",
    "    if md: res = display.Markdown(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0a43f",
   "metadata": {},
   "source": [
    "### Creating messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab553a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_msg(content, role='user', **kwargs):\n",
    "    \"Helper to create a `dict` appropriate for a message. `kwargs` are added as key/value pairs to the message\"\n",
    "    if hasattr(content, 'content'): content,role = content.content,content.role\n",
    "    if isinstance(content, ChatCompletion): return find_block(content)\n",
    "    return dict(role=role, content=content, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I'm Jeremy\"\n",
    "m = mk_msg(prompt)\n",
    "r = cli.create(messages=[m], model=model, max_tokens=100)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [mk_msg(prompt), mk_msg(r), mk_msg('I forgot my name. Can you remind me please?')]\n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c464f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli.create(messages=msgs, model=model, max_tokens=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f8a4d",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b873aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Client:\n",
    "    def __init__(self, model, cli=None):\n",
    "        \"Basic LLM messages client.\"\n",
    "        self.model,self.use = model,usage(0,0)\n",
    "        self.c = (cli or OpenAI()).chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(model)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _r(self:Client, r:ChatCompletion):\n",
    "    \"Store the result of the message and accrue total usage.\"\n",
    "    self.result = r\n",
    "    if getattr(r,'usage',None): self.use += r.usage\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36029ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_stream(r):\n",
    "    for o in r:\n",
    "        o = contents(o)\n",
    "        if o and isinstance(o, str): yield(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb96c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Completions.create)\n",
    "def __call__(self:Client,\n",
    "             msgs:list, # List of messages in the dialog\n",
    "             sp:str='', # System prompt\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             stream:bool=False, # Stream response?\n",
    "             **kwargs):\n",
    "    \"Make a call to LLM.\"\n",
    "    if stream: kwargs['stream_options'] = {\"include_usage\": True}\n",
    "    if sp: msgs = [mk_msg(sp, 'system')] + list(msgs)\n",
    "    r = self.c.create(\n",
    "        model=self.model, messages=msgs, max_tokens=maxtok, stream=stream, **kwargs)\n",
    "    if not stream: return self._r(r)\n",
    "    else: return get_stream(map(self._r, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47195b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [mk_msg('Hi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c3a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a92b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in c(msgs, stream=True): print(o, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7cdbc6",
   "metadata": {},
   "source": [
    "## Tool use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    a:int,  # First thing to sum\n",
    "    b:int # Second thing to sum\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    print(f\"Finding the sum of {a} and {b}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88420769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_openai_func(f): return dict(type='function', function=get_schema(f, 'parameters'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_tool_choice(f): return dict(type='function', function={'name':f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcab8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysp = \"You are a helpful assistant. When using tools, be sure to pass all required parameters, at minimum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\"\n",
    "tools=[mk_openai_func(sums)]\n",
    "tool_choice=mk_tool_choice(\"sums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [mk_msg(pr)]\n",
    "r = c(msgs, sp=sysp, tools=tools)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9394b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = find_block(r)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6488b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = m.tool_calls\n",
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = tc[0].function\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _mk_ns(*funcs:list[callable]) -> dict[str,callable]:\n",
    "    \"Create a `dict` of name to function in `funcs`, to use as a namespace\"\n",
    "    return {f.__name__:f for f in funcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def call_func(fc:types.chat.chat_completion_message_tool_call.Function, # Function block from message\n",
    "              ns:Optional[abc.Mapping]=None, # Namespace to search for tools, defaults to `globals()`\n",
    "              obj:Optional=None # Object to search for tools\n",
    "             ):\n",
    "    \"Call the function in the tool response `tr`, using namespace `ns`.\"\n",
    "    if ns is None: ns=globals()\n",
    "    if not isinstance(ns, abc.Mapping): ns = _mk_ns(*ns)\n",
    "    func = getattr(obj, fc.name, None)\n",
    "    if not func: func = ns[fc.name]\n",
    "    return func(**ast.literal_eval(fc.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = _mk_ns(sums)\n",
    "res = call_func(func, ns=ns)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_toolres(\n",
    "    r:abc.Mapping, # Tool use request response\n",
    "    ns:Optional[abc.Mapping]=None, # Namespace to search for tools\n",
    "    obj:Optional=None # Class to search for tools\n",
    "    ):\n",
    "    \"Create a `tool_result` message from response `r`.\"\n",
    "    r = mk_msg(r)\n",
    "    tcs = getattr(r, 'tool_calls', [])\n",
    "    res = [r]\n",
    "    for tc in (tcs or []):\n",
    "        func = tc.function\n",
    "        cts = str(call_func(func, ns=ns, obj=obj))\n",
    "        res.append(mk_msg(str(cts), 'tool', tool_call_id=tc.id, name=func.name))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13de1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = mk_toolres(r, ns=ns)\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc83c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs += tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed99502",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = c(msgs, sp=sysp, tools=tools)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy:\n",
    "    def sums(\n",
    "        self,\n",
    "        a:int,  # First thing to sum\n",
    "        b:int=1 # Second thing to sum\n",
    "    ) -> int: # The sum of the inputs\n",
    "        \"Adds a + b.\"\n",
    "        print(f\"Finding the sum of {a} and {b}\")\n",
    "        return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff70d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [mk_openai_func(Dummy.sums)]\n",
    "\n",
    "o = Dummy()\n",
    "msgs = mk_toolres(\"I'm Jeremy\")\n",
    "r = c(msgs, sp=sysp, tools=tools)\n",
    "msgs += mk_toolres(r, obj=o)\n",
    "res = c(msgs, sp=sysp, tools=tools)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [mk_openai_func(Dummy.sums)]\n",
    "\n",
    "o = Dummy()\n",
    "msgs = mk_toolres(pr)\n",
    "r = c(msgs, sp=sysp, tools=tools)\n",
    "msgs += mk_toolres(r, obj=o)\n",
    "res = c(msgs, sp=sysp, tools=tools)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "def _mock_id(): return 'call_' + ''.join(choices(ascii_letters+digits, k=24))\n",
    "\n",
    "def mock_tooluse(name:str, # The name of the called function\n",
    "                 res,  # The result of calling the function\n",
    "                 **kwargs): # The arguments to the function\n",
    "    \"\"\n",
    "    id = _mock_id()\n",
    "    func = dict(arguments=json.dumps(kwargs), name=name)\n",
    "    tc = dict(id=id, function=func, type='function')\n",
    "    req = dict(content=None, role='assistant', tool_calls=[tc])\n",
    "    resp = mk_msg('' if res is None else str(res), 'tool', tool_call_id=id, name=name)\n",
    "    return [req,resp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f693c",
   "metadata": {},
   "source": [
    "This function mocks the messages needed to implement tool use, for situations where you want to insert tool use messages into a dialog without actually calling into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcee006",
   "metadata": {},
   "outputs": [],
   "source": [
    "tu = mk_tooluse(name='sums', res=7063474, a=604542, b=6458932)\n",
    "r = c([mk_msg(pr)]+tu, tools=tools)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea144b8",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Chat:\n",
    "    def __init__(self,\n",
    "                 model:Optional[str]=None, # Model to use (leave empty if passing `cli`)\n",
    "                 cli:Optional[Client]=None, # Client to use (leave empty if passing `model`)\n",
    "                 sp='', # Optional system prompt\n",
    "                 tools:Optional[list]=None,  # List of tools to make available\n",
    "                 tool_choice:Optional[str]=None): # Forced tool choice\n",
    "        \"OpenAI chat client.\"\n",
    "        assert model or cli\n",
    "        self.c = (cli or Client(model))\n",
    "        self.h,self.sp,self.tools,self.tool_choice = [],sp,tools,tool_choice\n",
    "    \n",
    "    @property\n",
    "    def use(self): return self.c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = \"Never mention what tools you use.\"\n",
    "chat = Chat(model, sp=sp)\n",
    "chat.c.use, chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403539e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Completions.create)\n",
    "def __call__(self:Chat,\n",
    "             pr=None,  # Prompt / message\n",
    "             stream:bool=False, # Stream response?\n",
    "             **kwargs):\n",
    "    \"Add prompt `pr` to dialog and get a response\"\n",
    "    if isinstance(pr,str): pr = pr.strip()\n",
    "    if pr: self.h.append(mk_msg(pr))\n",
    "    if self.tools: kwargs['tools'] = [mk_openai_func(o) for o in self.tools]\n",
    "    if self.tool_choice: kwargs['tool_choice'] = mk_tool_choice(tool_choice)\n",
    "    res = self.c(self.h, sp=self.sp, stream=stream, **kwargs)\n",
    "    self.h += mk_toolres(res, ns=self.tools, obj=self)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40073f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat(\"I'm Jeremy\")\n",
    "chat(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529104ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model, sp=sp)\n",
    "for o in chat(\"I'm Jeremy\", stream=True):\n",
    "    o = contents(o)\n",
    "    if o and isinstance(o, str): print(o, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40892f",
   "metadata": {},
   "source": [
    "### Chat tool use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6535cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = f\"What is {a}+{b}?\"\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797741c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat(model, sp=sp, tools=[sums])\n",
    "r = chat(pr)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1dd4c3",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf741dbc",
   "metadata": {},
   "source": [
    "As everyone knows, when testing image APIs you have to use a cute puppy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image is Cute_dog.jpg from Wikimedia\n",
    "fn = Path('samples/puppy.jpg')\n",
    "display.Image(filename=fn, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fn.read_bytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18ee71",
   "metadata": {},
   "source": [
    "```js\n",
    "{\n",
    "  \"type\": \"image_url\",\n",
    "  \"image_url\": {\n",
    "    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def img_msg(data:bytes)->dict:\n",
    "    \"Convert image `data` into an encoded `dict`\"\n",
    "    img = base64.b64encode(data).decode(\"utf-8\")\n",
    "    mtype = mimetypes.types_map['.'+imghdr.what(None, h=data)]\n",
    "    r = {'url': f\"data:{mtype};base64,{img}\"}\n",
    "    return {'type': \"image_url\", \"image_url\": r}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def text_msg(s:str)->dict:\n",
    "    \"Convert `s` to a text message\"\n",
    "    return {\"type\": \"text\", \"text\": s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0eed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"In brief, what color flowers are in this image?\"\n",
    "msg = mk_msg([img_msg(img), text_msg(q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c([msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _mk_content(src):\n",
    "    \"Create appropriate content data structure based on type of content\"\n",
    "    if isinstance(src,str): return text_msg(src)\n",
    "    if isinstance(src,bytes): return img_msg(src)\n",
    "    return src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67923d1",
   "metadata": {},
   "source": [
    "There's not need to manually choose the type of message, since we figure that out from the data of the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccff61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_mk_content('Hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d12bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_msg(content, # A string, list, or dict containing the contents of the message\n",
    "           role='user', # Must be 'user' or 'assistant'\n",
    "           **kwargs):\n",
    "    \"Helper to create a `dict` appropriate for a message. `kwargs` are added as key/value pairs to the message\"\n",
    "    if hasattr(content, 'content'): content,role = content.content,content.role\n",
    "    if isinstance(content, ChatCompletion): return find_block(content)\n",
    "    if content is not None and not isinstance(content, list): content=[content]\n",
    "    content = [_mk_content(o) for o in content] if content else ''\n",
    "    return dict(role=role, content=content, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ea0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c([mk_msg([img, q])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
