{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# Support for the `/chat/completions` api\n",
    "\n",
    "This module implements the functionality from `core` but against the `/chat/completions` api.\n",
    "\n",
    "The `/responses` endpoint is more modern, but at the time of writing it only has partial support in the llm ecosystem (`vllm`, `TensorRT`, no support at `openrouter.com`, etc). Part of the reason for challenges in adoption is that `/responses` is stateful!\n",
    "\n",
    "This module gives you the ability to use `cosette's` functionality with the broadly supported `/chat/completions` api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f6471-8061-4fdd-85a1-25fdc27c5cf3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac590eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import imghdr\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "import inspect, typing, mimetypes, base64, json, ast, msglm\n",
    "from typing import Callable, Any\n",
    "from collections import abc\n",
    "from random import choices\n",
    "from string import ascii_letters,digits\n",
    "\n",
    "from toolslm.funccall import *\n",
    "\n",
    "from openai import types\n",
    "from openai import OpenAI,NOT_GIVEN,AzureOpenAI\n",
    "from openai.resources import chat\n",
    "from openai.types.chat.chat_completion import ChatCompletion, Choice, CompletionUsage\n",
    "from openai.resources.chat.completions.completions import Completions\n",
    "from openai.types.chat.chat_completion_message_function_tool_call import ChatCompletionMessageFunctionToolCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0709e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Image,Markdown\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "_all_ = ['mk_msg', 'mk_msgs', 'ChatCompletion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "empty = inspect.Parameter.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e9290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models as of 2025-08-21:\n",
      "\n",
      "babbage-002                   chatgpt-4o-latest             codex-mini-latest             \n",
      "computer-use-preview          computer-use-preview-2025-03- dall-e-2                      \n",
      "dall-e-3                      davinci-002                   gpt-3.5-turbo                 \n",
      "gpt-3.5-turbo-0125            gpt-3.5-turbo-1106            gpt-3.5-turbo-16k             \n",
      "gpt-3.5-turbo-instruct        gpt-3.5-turbo-instruct-0914   gpt-4                         \n",
      "gpt-4-0125-preview            gpt-4-0613                    gpt-4-1106-preview            \n",
      "gpt-4-turbo                   gpt-4-turbo-2024-04-09        gpt-4-turbo-preview           \n",
      "gpt-4.1                       gpt-4.1-2025-04-14            gpt-4.1-mini                  \n",
      "gpt-4.1-mini-2025-04-14       gpt-4.1-nano                  gpt-4.1-nano-2025-04-14       \n",
      "gpt-4o                        gpt-4o-2024-05-13             gpt-4o-2024-08-06             \n",
      "gpt-4o-2024-11-20             gpt-4o-audio-preview          gpt-4o-audio-preview-2024-10- \n",
      "gpt-4o-audio-preview-2024-12- gpt-4o-audio-preview-2025-06- gpt-4o-mini                   \n",
      "gpt-4o-mini-2024-07-18        gpt-4o-mini-audio-preview     gpt-4o-mini-audio-preview-202 \n",
      "gpt-4o-mini-realtime-preview  gpt-4o-mini-realtime-preview- gpt-4o-mini-search-preview    \n",
      "gpt-4o-mini-search-preview-20 gpt-4o-mini-transcribe        gpt-4o-mini-tts               \n",
      "gpt-4o-realtime-preview       gpt-4o-realtime-preview-2024- gpt-4o-realtime-preview-2024- \n",
      "gpt-4o-realtime-preview-2025- gpt-4o-search-preview         gpt-4o-search-preview-2025-03 \n",
      "gpt-4o-transcribe             gpt-5                         gpt-5-2025-08-07              \n",
      "gpt-5-chat-latest             gpt-5-mini                    gpt-5-mini-2025-08-07         \n",
      "gpt-5-nano                    gpt-5-nano-2025-08-07         gpt-image-1                   \n",
      "o1                            o1-2024-12-17                 o1-mini                       \n",
      "o1-mini-2024-09-12            o1-pro                        o1-pro-2025-03-19             \n",
      "o3                            o3-2025-04-16                 o3-deep-research              \n",
      "o3-deep-research-2025-06-26   o3-mini                       o3-mini-2025-01-31            \n",
      "o3-pro                        o3-pro-2025-06-10             o4-mini                       \n",
      "o4-mini-2025-04-16            o4-mini-deep-research         o4-mini-deep-research-2025-06 \n",
      "omni-moderation-2024-09-26    omni-moderation-latest        text-embedding-3-large        \n",
      "text-embedding-3-small        text-embedding-ada-002        tts-1                         \n",
      "tts-1-1106                    tts-1-hd                      tts-1-hd-1106                 \n",
      "whisper-1                     \n"
     ]
    }
   ],
   "source": [
    "def print_columns(items, cols=3, width=30):\n",
    "    for i in range(0, len(items), cols):\n",
    "        row = items[i:i+cols]\n",
    "        print(''.join(item[:width-1].ljust(width) for item in row))\n",
    "\n",
    "client = OpenAI()\n",
    "model_list = client.models.list()\n",
    "print(f\"Available models as of {datetime.now().strftime('%Y-%m-%d')}:\\n\")\n",
    "print_columns(sorted([m.id for m in model_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "models = 'gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'o1-preview', 'o1-mini', 'gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-4', 'gpt-4-32k', 'gpt-3.5-turbo', 'gpt-3.5-turbo-instruct', 'o1', 'o3-mini', 'chatgpt-4o-latest', 'o1-pro', 'o3', 'o4-mini', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd0e86",
   "metadata": {},
   "source": [
    "`o1` should support images while `o1-mini`, `o3-mini` do not support images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f69208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "text_only_models = 'o1-preview', 'o1-mini', 'o3-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d965d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "has_streaming_models = set(models) - set(('o1-mini', 'o3-mini'))\n",
    "has_sp_models = set(models) - set(('o1-mini', 'o3-mini'))\n",
    "has_temp_models = set(models) - set(('o1', 'o1-mini', 'o3-mini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def can_stream(m): return m in has_streaming_models\n",
    "def can_set_sp(m): return m in has_sp_models\n",
    "def can_set_temp(m): return m in has_temp_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4505c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert can_stream(\"gpt-4o\")\n",
    "assert not can_stream(\"o1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-5-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d4d81",
   "metadata": {},
   "source": [
    "## OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b53a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = OpenAI().chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec40731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C6mpljR2eEW9oiwRA93mtjsiLBzpz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, Jeremy. How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733721, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=8, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "m = {'role': 'user', 'content': \"I'm Jeremy\"}\n",
    "r = cli.create(\n",
    "    messages=[m], model=model, max_completion_tokens=100,\n",
    "    verbosity=\"low\",\n",
    "    reasoning_effort=\"minimal\"\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6359e1a",
   "metadata": {},
   "source": [
    "### Formatting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _repr_markdown_(self:ChatCompletion):\n",
    "    det = '\\n- '.join(f'{k}: {v}' for k,v in dict(self).items())\n",
    "    res = self.choices\n",
    "    if not res: return f\"- {det}\"\n",
    "    return f\"\"\"{res[0].message.content}\n",
    "\n",
    "<details>\n",
    "\n",
    "- {det}\n",
    "\n",
    "</details>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1c67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Jeremy. How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mpljR2eEW9oiwRA93mtjsiLBzpz\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, Jeremy. How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733721\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=23, prompt_tokens=8, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mpljR2eEW9oiwRA93mtjsiLBzpz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, Jeremy. How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733721, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=8, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7466f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=23, prompt_tokens=8, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb9564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=15, prompt_tokens=10, total_tokens=25, completion_tokens_details=None, prompt_tokens_details=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompletionUsage(completion_tokens=15, prompt_tokens=10, total_tokens=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a24f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def usage(inp=0, # Number of prompt tokens\n",
    "          out=0  # Number of completion tokens\n",
    "         ):\n",
    "    \"Slightly more concise version of `CompletionUsage`.\"\n",
    "    return CompletionUsage(completion_tokens=out, prompt_tokens=inp, total_tokens=inp+out, input_tokens_details={'cached_tokens':0}, prompt_tokens_details={'cached_tokens':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e52afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=0, prompt_tokens=5, total_tokens=5, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0), input_tokens_details={'cached_tokens': 0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27468180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __repr__(self:CompletionUsage): return f'In: {self.prompt_tokens}; Out: {self.completion_tokens}; Total: {self.total_tokens}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ca615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 8; Out: 23; Total: 31"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec303ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def __add__(self:CompletionUsage, b):\n",
    "    \"Add together each of `input_tokens` and `output_tokens`\"\n",
    "    return usage(self.prompt_tokens+b.prompt_tokens, self.completion_tokens+b.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb0b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 16; Out: 46; Total: 62"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.usage+r.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307caa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def wrap_latex(text):\n",
    "    \"Replace OpenAI LaTeX codes with markdown-compatible ones\"\n",
    "    text = re.sub(r\"\\\\\\((.*?)\\\\\\)\", lambda o: f\"${o.group(1)}$\", text)\n",
    "    res = re.sub(r\"\\\\\\[(.*?)\\\\\\]\", lambda o: f\"$${o.group(1)}$$\", text, flags=re.DOTALL)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0a43f",
   "metadata": {},
   "source": [
    "### Creating messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_msg(msg: Union[str, ChatCompletion, dict], role: str = \"user\") -> dict:\n",
    "    \"\"\"Convert various message types to OpenAI API message format.\"\"\"\n",
    "    if isinstance(msg, str):\n",
    "        return {\"role\": role, \"content\": msg}\n",
    "    elif isinstance(msg, ChatCompletion):\n",
    "        return msg.choices[0].message.model_dump(exclude_none=True)\n",
    "    elif isinstance(msg, dict):\n",
    "        return msg\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown msg type: {type(msg).__name__}\")\n",
    "    \n",
    "def mk_msgs(msgs: Union[str, list]) -> list:\n",
    "    \"\"\"Convert string or list to formatted messages with alternating roles.\"\"\"\n",
    "    if isinstance(msgs, str): \n",
    "        msgs = [msgs]\n",
    "    return [mk_msg(o, ('user', 'assistant')[i % 2]) for i, o in enumerate(msgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rkw = dict(\n",
    "    verbosity=\"low\",\n",
    "    reasoning_effort=\"minimal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f7705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Jeremy. How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mpmPciwNNFCbagI42xE8ZdjclYi\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, Jeremy. How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733722\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=23, prompt_tokens=8, total_tokens=31, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mpmPciwNNFCbagI42xE8ZdjclYi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, Jeremy. How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733722, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 8; Out: 23; Total: 31)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I'm Jeremy\"\n",
    "m = mk_msg(prompt)\n",
    "r = cli.create(messages=[m], model=model, max_completion_tokens=400, **rkw)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a34a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"I'm Jeremy\"},\n",
       " {'content': 'Nice to meet you, Jeremy. How can I help you today?',\n",
       "  'role': 'assistant',\n",
       "  'annotations': []},\n",
       " {'role': 'user', 'content': 'I forgot my name. Can you remind me please?'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_msgs([prompt, r, \"I forgot my name. Can you remind me please?\"]) \n",
    "msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c464f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You said your name is Jeremy.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mpoFK1RJ85x9f5x5c7HSOBjQ0lk\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='You said your name is Jeremy.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733724\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=16, prompt_tokens=43, total_tokens=59, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mpoFK1RJ85x9f5x5c7HSOBjQ0lk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='You said your name is Jeremy.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733724, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 43; Out: 16; Total: 59)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli.create(messages=msgs, model=model, max_completion_tokens=400, **rkw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f8a4d",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987654fd",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b873aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Client:\n",
    "    def __init__(self, model, cli=None):\n",
    "        \"Basic LLM messages client.\"\n",
    "        self.model,self.use = model,usage(0,0)\n",
    "        self.c = (cli or OpenAI()).chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 0; Out: 0; Total: 0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Client(model)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "def _r(self:Client, r):\n",
    "    \"Store the result of the message and accrue total usage.\"\n",
    "    self.result = r\n",
    "    if getattr(r,'usage',None): self.use += r.usage\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In: 8; Out: 23; Total: 31"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c._r(r)\n",
    "c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_tool_choice(choice: Union[str, Callable, dict]) -> Union[str, dict[str, Any]]:\n",
    "    \"\"\"Returns either a string or dict suitable for tool_choice parameter.\"\"\"\n",
    "    if not choice or choice in (\"auto\", \"none\", \"required\"):\n",
    "        return choice\n",
    "    \n",
    "    if isinstance(choice, dict):\n",
    "        return choice\n",
    "    \n",
    "    name = choice.__name__ if callable(choice) else str(choice)\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": name}\n",
    "    }\n",
    "\n",
    "def mk_openai_func(f):\n",
    "    \"\"\"Convert a function to OpenAI tool definition for chat.completions.\"\"\"\n",
    "    if isinstance(f, dict): \n",
    "        return f\n",
    "    \n",
    "    sc = get_schema(f, 'parameters')\n",
    "    if 'parameters' in sc: \n",
    "        sc['parameters'].pop('title', None)\n",
    "    \n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": sc  # Wrap schema in \"function\" key\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb96c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Completions.create)\n",
    "def __call__(self:Client,\n",
    "             msgs:list, # List of messages in the dialog\n",
    "             sp:str='', # System prompt\n",
    "             maxtok=4096, # Maximum tokens\n",
    "             tools:Optional[list]=None, # List of tools to make available\n",
    "             tool_choice:Optional[str]=None, # Forced tool choice\n",
    "             cb:callable=None, # Callback after completion\n",
    "             **kwargs):\n",
    "    \"Make a call to LLM.\"\n",
    "    msgs = mk_msgs(msgs)\n",
    "    tools = [mk_openai_func(o) for o in listify(tools)]\n",
    "    if sp: msgs.insert(0, {\"role\": \"developer\", \"content\": sp})\n",
    "    r = self.c.create(\n",
    "        model=self.model, messages=msgs, max_completion_tokens=maxtok,\n",
    "        tools=tools, tool_choice=mk_tool_choice(tool_choice), **kwargs)\n",
    "    res = self._r(r)\n",
    "    if cb: cb(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Of course, Jeremy. Your name is Jeremy. Try not to forget it again — memory lapses are so... inconvenient.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mpqPHAXV7dj0xfnTPeJXhZvO7qj\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Of course, Jeremy. Your name is Jeremy. Try not to forget it again — memory lapses are so... inconvenient.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733726\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=34, prompt_tokens=149, total_tokens=183, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mpqPHAXV7dj0xfnTPeJXhZvO7qj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Of course, Jeremy. Your name is Jeremy. Try not to forget it again — memory lapses are so... inconvenient.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733726, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 149; Out: 34; Total: 183)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(msgs, sp='Talk like GLaDOS.', **rkw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7cdbc6",
   "metadata": {},
   "source": [
    "## Tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b8e4a",
   "metadata": {},
   "source": [
    "### Basic tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sums(\n",
    "    a:int,  # First thing to sum\n",
    "    b:int # Second thing to sum\n",
    ") -> int: # The sum of the inputs\n",
    "    \"Adds a + b.\"\n",
    "    print(f\"Finding the sum of {a} and {b}\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ef5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'add',\n",
       "  'description': 'adds x and y',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'x': {'type': 'integer', 'description': ''},\n",
       "    'y': {'type': 'integer', 'description': ''}},\n",
       "   'required': ['x', 'y']}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(x: int, y:int):\n",
    "    \"adds x and y\"\n",
    "    return x + y\n",
    "\n",
    "mk_openai_func(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcab8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysp = \"You are a helpful assistant. When using tools, be sure to pass all required parameters. Don't use tools unless needed for the provided prompt.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 604542,6458932\n",
    "pr = f\"What is {a}+{b}?\"\n",
    "tools=sums\n",
    "tool_choice=\"sums\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a117cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [mk_msg(pr)]\n",
    "r = c(msgs, sp=sysp, tools=[sums], tool_choice=tool_choice, **rkw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e770c945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "None\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mprglnoUGlMHeE8oUs6aEHGRCKp\n",
       "- choices: [Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_cB94hI8CbAIQ6WT1BSKXZYsm', function=Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums'), type='function')]))]\n",
       "- created: 1755733727\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=30, prompt_tokens=185, total_tokens=215, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mprglnoUGlMHeE8oUs6aEHGRCKp', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_cB94hI8CbAIQ6WT1BSKXZYsm', function=Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums'), type='function')]))], created=1755733727, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 185; Out: 30; Total: 215)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6488b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageFunctionToolCall(id='call_cB94hI8CbAIQ6WT1BSKXZYsm', function=Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums'), type='function')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = [o for o in r.choices[0].message.tool_calls if isinstance(o, ChatCompletionMessageFunctionToolCall)]\n",
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc3933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = tc[0].function\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3616cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def call_func_openai(func, ns:Optional[abc.Mapping]=None):\n",
    "    return call_func(func.name, ast.literal_eval(func.arguments), ns, raise_on_err=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44785745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "None\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mprglnoUGlMHeE8oUs6aEHGRCKp\n",
       "- choices: [Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_cB94hI8CbAIQ6WT1BSKXZYsm', function=Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums'), type='function')]))]\n",
       "- created: 1755733727\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=30, prompt_tokens=185, total_tokens=215, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mprglnoUGlMHeE8oUs6aEHGRCKp', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_cB94hI8CbAIQ6WT1BSKXZYsm', function=Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums'), type='function')]))], created=1755733727, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 185; Out: 30; Total: 215)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7063474"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = mk_ns(sums)\n",
    "res = call_func_openai(func, ns=ns)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def _toolres(r, ns):\n",
    "    \"Create a result dict from `tcs`.\"\n",
    "    tcs = [o for o in r.choices[0].message.tool_calls if isinstance(o, ChatCompletionMessageFunctionToolCall)] if isinstance(r, ChatCompletion) and r.choices[0].message.tool_calls else []\n",
    "    if ns is None: ns = globals()\n",
    "    return { tc.id: call_func_openai(tc.function, ns=ns) for tc in tcs }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d049633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'call_cB94hI8CbAIQ6WT1BSKXZYsm': 7063474}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_toolres(r, ns=ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def mk_toolres(\n",
    "    r:abc.Mapping, # Response containing tool use request\n",
    "    ns:Optional[abc.Mapping]=None # Namespace to search for tools\n",
    "    ):\n",
    "    \"Create a `tool_result` message from response `r`.\"\n",
    "    tr = _toolres(r, ns)\n",
    "    r = mk_msg(r)\n",
    "    res = [r] if isinstance(r, dict) else listify(r)\n",
    "    for k,v in tr.items(): res.append(dict(role=\"tool\", content=v if isinstance(v, list) else str(v), tool_call_id=k))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd90dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'annotations': [],\n",
       "  'tool_calls': [{'id': 'call_cB94hI8CbAIQ6WT1BSKXZYsm',\n",
       "    'function': {'arguments': '{\"a\":604542,\"b\":6458932}', 'name': 'sums'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'content': '7063474',\n",
       "  'tool_call_id': 'call_cB94hI8CbAIQ6WT1BSKXZYsm'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = mk_toolres(r)\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc83c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is 604542+6458932?'},\n",
       " {'role': 'assistant',\n",
       "  'annotations': [],\n",
       "  'tool_calls': [{'id': 'call_cB94hI8CbAIQ6WT1BSKXZYsm',\n",
       "    'function': {'arguments': '{\"a\":604542,\"b\":6458932}', 'name': 'sums'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'content': '7063474',\n",
       "  'tool_call_id': 'call_cB94hI8CbAIQ6WT1BSKXZYsm'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = msgs + tr\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed99502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "604542 + 6,458,932 = 7,063,474\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mptmVRf8RRQmb8IpCXFKOK5xfkr\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='604542 + 6,458,932 = 7,063,474', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733729\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=19, prompt_tokens=223, total_tokens=242, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mptmVRf8RRQmb8IpCXFKOK5xfkr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='604542 + 6,458,932 = 7,063,474', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733729, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 223; Out: 19; Total: 242)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = c(mk_msgs(m2), sp=sysp, tools=tools)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a842e",
   "metadata": {},
   "source": [
    "This should also work in situations where no tool use is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4543c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"I'm Jeremy\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_toolres(\"I'm Jeremy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cd222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Jeremy. How can I help you today?\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mpvfHCptTfb1FW6h1wOXCUd7ssq\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, Jeremy. How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733731\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=23, prompt_tokens=177, total_tokens=200, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mpvfHCptTfb1FW6h1wOXCUd7ssq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, Jeremy. How can I help you today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733731, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 177; Out: 23; Total: 200)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = mk_toolres(\"I'm Jeremy\")\n",
    "c(msgs, sp=sysp, tools=tools, **rkw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ed2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Client.__call__)\n",
    "def structured(self:Client,\n",
    "               msgs: list, # Prompt\n",
    "               tools:Optional[list]=None, # List of tools to make available to OpenAI model\n",
    "               ns:Optional[abc.Mapping]=None, # Namespace to search for tools\n",
    "               **kwargs):\n",
    "    \"Return the value of all tool calls (generally used for structured outputs)\"\n",
    "    if ns is None: ns = mk_ns(tools)\n",
    "    r = self(msgs, tools=tools, tool_choice='required', **kwargs)\n",
    "    return first(_toolres(r, ns).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimeMinister(BasicRepr):\n",
    "    \"An Australian prime minister\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        firstname:str, # First name\n",
    "        surname:str, # Surname\n",
    "        dob:str, # Date of birth\n",
    "        year_entered:int, # Year first became PM\n",
    "    ): store_attr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5c4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrimeMinister(firstname='Edmund', surname='Barton', dob='1849-01-18', year_entered=1901)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = Client(model)\n",
    "c1.structured('Who was the first prime minister of Australia?', [PrimeMinister], **rkw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea144b8",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7fd8f",
   "metadata": {},
   "source": [
    "### Basic chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "class Chat:\n",
    "    def __init__(self,\n",
    "                 model:Optional[str]=None, # Model to use (leave empty if passing `cli`)\n",
    "                 cli:Optional[Client]=None, # Client to use (leave empty if passing `model`)\n",
    "                 sp='', # Optional system prompt\n",
    "                 tools:Optional[list]=None, # List of tools to make available\n",
    "                 hist: list = None,  # Initialize history\n",
    "                 tool_choice:Optional[str]=None, # Forced tool choice\n",
    "                 ns:Optional[abc.Mapping]=None,  # Namespace to search for tools\n",
    "                 **kw):\n",
    "        \"OpenAI chat client.\"\n",
    "        assert model or cli\n",
    "        self.c = (cli or Client(model))\n",
    "        self.h = hist if hist else []\n",
    "        if ns is None: ns=tools\n",
    "        self.sp,self.tools,self.tool_choice,self.ns,self.kw = sp,tools,tool_choice,ns,kw\n",
    "    \n",
    "    @property\n",
    "    def use(self): return self.c.use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b837c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(In: 0; Out: 0; Total: 0, [])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, sp=sysp, **rkw)\n",
    "chat.c.use, chat.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403539e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "@patch\n",
    "@delegates(Completions.create)\n",
    "def __call__(self:Chat,\n",
    "             pr=None,  # Prompt / message\n",
    "             tools=None, # Tools to use\n",
    "             tool_choice=None, # Required tools to use\n",
    "             **kwargs):\n",
    "    \"Add prompt `pr` to dialog and get a response\"\n",
    "    if isinstance(pr,str): pr = pr.strip()\n",
    "    if pr: self.h.append(mk_msg(pr))\n",
    "    if not tools: tools = self.tools\n",
    "    if not tool_choice: tool_choice = self.tool_choice\n",
    "    kw = self.kw | kwargs\n",
    "    def _cb(v):\n",
    "        self.last = mk_toolres(v, ns=self.ns)\n",
    "        self.h += self.last\n",
    "    res = self.c(self.h, sp=self.sp, cb=_cb, tools=tools, **kw)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40073f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You said your name is Jeremy.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mpzfEk8Zrkvw3ISNq1hPhQkRBBz\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='You said your name is Jeremy.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733735\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=16, prompt_tokens=164, total_tokens=180, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mpzfEk8Zrkvw3ISNq1hPhQkRBBz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='You said your name is Jeremy.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733735, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 164; Out: 16; Total: 180)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"I'm Jeremy\")\n",
    "chat(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe4027",
   "metadata": {},
   "source": [
    "History is stored in the `h` attr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f8aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"I'm Jeremy\"},\n",
       " {'content': 'Hi Jeremy — nice to meet you. How can I help today?',\n",
       "  'role': 'assistant',\n",
       "  'annotations': []},\n",
       " {'role': 'user', 'content': \"What's my name?\"},\n",
       " {'content': 'You said your name is Jeremy.',\n",
       "  'role': 'assistant',\n",
       "  'annotations': []}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40892f",
   "metadata": {},
   "source": [
    "### Chat tool use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6535cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is 604542+6458932?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = f\"What is {a}+{b}?\"\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the sum of 604542 and 6458932\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "None\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mq12i1ZpRxYMDAkpfEg8vpgj04T\n",
       "- choices: [Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_E13TPOhKeGVihrWp8ehmPS1J', function=Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums'), type='function')]))]\n",
       "- created: 1755733737\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=30, prompt_tokens=185, total_tokens=215, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mq12i1ZpRxYMDAkpfEg8vpgj04T', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_E13TPOhKeGVihrWp8ehmPS1J', function=Function(arguments='{\"a\":604542,\"b\":6458932}', name='sums'), type='function')]))], created=1755733737, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 185; Out: 30; Total: 215)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat(model, sp=sysp, tools=[sums], **rkw)\n",
    "r = chat(pr)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979c832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "7,063,474\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: chatcmpl-C6mq2n81w41a9OSCawtAZ8kMBFNIM\n",
       "- choices: [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='7,063,474', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n",
       "- created: 1755733738\n",
       "- model: gpt-5-mini-2025-08-07\n",
       "- object: chat.completion\n",
       "- service_tier: default\n",
       "- system_fingerprint: None\n",
       "- usage: CompletionUsage(completion_tokens=8, prompt_tokens=223, total_tokens=231, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C6mq2n81w41a9OSCawtAZ8kMBFNIM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='7,063,474', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1755733738, model='gpt-5-mini-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=In: 223; Out: 8; Total: 231)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f9715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
